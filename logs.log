2024-11-27 19:50:38,722:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\scipy\__init__.py:159: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 2.0.2)
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"

2024-11-27 20:02:54,558:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:02:54,558:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:02:54,558:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:02:54,558:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:04:42,623:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:04:42,623:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:04:42,623:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:04:42,623:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:04:47,709:INFO:PyCaret ClassificationExperiment
2024-11-27 20:04:47,709:INFO:Logging name: clf-default-name
2024-11-27 20:04:47,709:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-27 20:04:47,709:INFO:version 3.3.2
2024-11-27 20:04:47,709:INFO:Initializing setup()
2024-11-27 20:04:47,709:INFO:self.USI: 5e16
2024-11-27 20:04:47,709:INFO:self._variable_keys: {'seed', 'y_train', 'X_test', 'idx', 'data', 'X', 'is_multiclass', '_ml_usecase', 'exp_name_log', 'logging_param', 'fix_imbalance', '_available_plots', 'gpu_n_jobs_param', 'pipeline', 'fold_groups_param', 'html_param', 'target_param', 'fold_generator', 'exp_id', 'fold_shuffle_param', 'gpu_param', 'y_test', 'memory', 'USI', 'X_train', 'log_plots_param', 'y', 'n_jobs_param'}
2024-11-27 20:04:47,709:INFO:Checking environment
2024-11-27 20:04:47,709:INFO:python_version: 3.9.1
2024-11-27 20:04:47,709:INFO:python_build: ('tags/v3.9.1:1e5d33e', 'Dec  7 2020 17:08:21')
2024-11-27 20:04:47,709:INFO:machine: AMD64
2024-11-27 20:04:47,709:INFO:platform: Windows-10-10.0.18362-SP0
2024-11-27 20:04:47,711:INFO:Memory: svmem(total=16973832192, available=10423554048, percent=38.6, used=6550278144, free=10423554048)
2024-11-27 20:04:47,711:INFO:Physical Core: 6
2024-11-27 20:04:47,711:INFO:Logical Core: 12
2024-11-27 20:04:47,711:INFO:Checking libraries
2024-11-27 20:04:47,711:INFO:System:
2024-11-27 20:04:47,711:INFO:    python: 3.9.1 (tags/v3.9.1:1e5d33e, Dec  7 2020, 17:08:21) [MSC v.1927 64 bit (AMD64)]
2024-11-27 20:04:47,711:INFO:executable: c:\users\user\appdata\local\programs\python\python39\python.exe
2024-11-27 20:04:47,711:INFO:   machine: Windows-10-10.0.18362-SP0
2024-11-27 20:04:47,711:INFO:PyCaret required dependencies:
2024-11-27 20:04:47,724:INFO:                 pip: 24.3.1
2024-11-27 20:04:47,724:INFO:          setuptools: 75.6.0
2024-11-27 20:04:47,724:INFO:             pycaret: 3.3.2
2024-11-27 20:04:47,724:INFO:             IPython: 8.18.1
2024-11-27 20:04:47,724:INFO:          ipywidgets: 8.1.5
2024-11-27 20:04:47,724:INFO:                tqdm: 4.67.1
2024-11-27 20:04:47,724:INFO:               numpy: 1.21.6
2024-11-27 20:04:47,724:INFO:              pandas: 1.3.5
2024-11-27 20:04:47,724:INFO:              jinja2: 3.1.4
2024-11-27 20:04:47,724:INFO:               scipy: 1.7.3
2024-11-27 20:04:47,724:INFO:              joblib: 1.3.2
2024-11-27 20:04:47,724:INFO:             sklearn: 1.4.2
2024-11-27 20:04:47,724:INFO:                pyod: 2.0.2
2024-11-27 20:04:47,724:INFO:            imblearn: 0.12.4
2024-11-27 20:04:47,724:INFO:   category_encoders: 2.6.4
2024-11-27 20:04:47,724:INFO:            lightgbm: 4.5.0
2024-11-27 20:04:47,724:INFO:               numba: 0.58.0
2024-11-27 20:04:47,724:INFO:            requests: 2.32.3
2024-11-27 20:04:47,724:INFO:          matplotlib: 3.7.5
2024-11-27 20:04:47,724:INFO:          scikitplot: 0.3.7
2024-11-27 20:04:47,724:INFO:         yellowbrick: 1.5
2024-11-27 20:04:47,724:INFO:              plotly: 5.24.1
2024-11-27 20:04:47,724:INFO:    plotly-resampler: Not installed
2024-11-27 20:04:47,724:INFO:             kaleido: 0.2.1
2024-11-27 20:04:47,724:INFO:           schemdraw: 0.15
2024-11-27 20:04:47,724:INFO:         statsmodels: 0.14.1
2024-11-27 20:04:47,724:INFO:              sktime: 0.26.0
2024-11-27 20:04:47,724:INFO:               tbats: 1.1.3
2024-11-27 20:04:47,724:INFO:            pmdarima: 2.0.4
2024-11-27 20:04:47,724:INFO:              psutil: 6.1.0
2024-11-27 20:04:47,724:INFO:          markupsafe: 3.0.2
2024-11-27 20:04:47,724:INFO:             pickle5: Not installed
2024-11-27 20:04:47,724:INFO:         cloudpickle: 3.1.0
2024-11-27 20:04:47,724:INFO:         deprecation: 2.1.0
2024-11-27 20:04:47,724:INFO:              xxhash: 3.5.0
2024-11-27 20:04:47,724:INFO:           wurlitzer: Not installed
2024-11-27 20:04:47,724:INFO:PyCaret optional dependencies:
2024-11-27 20:04:47,724:INFO:                shap: Not installed
2024-11-27 20:04:47,724:INFO:           interpret: Not installed
2024-11-27 20:04:47,724:INFO:                umap: Not installed
2024-11-27 20:04:47,724:INFO:     ydata_profiling: Not installed
2024-11-27 20:04:47,724:INFO:  explainerdashboard: Not installed
2024-11-27 20:04:47,724:INFO:             autoviz: Not installed
2024-11-27 20:04:47,724:INFO:           fairlearn: Not installed
2024-11-27 20:04:47,724:INFO:          deepchecks: Not installed
2024-11-27 20:04:47,724:INFO:             xgboost: Not installed
2024-11-27 20:04:47,724:INFO:            catboost: Not installed
2024-11-27 20:04:47,724:INFO:              kmodes: Not installed
2024-11-27 20:04:47,724:INFO:             mlxtend: Not installed
2024-11-27 20:04:47,724:INFO:       statsforecast: Not installed
2024-11-27 20:04:47,724:INFO:        tune_sklearn: Not installed
2024-11-27 20:04:47,724:INFO:                 ray: Not installed
2024-11-27 20:04:47,724:INFO:            hyperopt: Not installed
2024-11-27 20:04:47,724:INFO:              optuna: Not installed
2024-11-27 20:04:47,724:INFO:               skopt: Not installed
2024-11-27 20:04:47,724:INFO:              mlflow: Not installed
2024-11-27 20:04:47,724:INFO:              gradio: Not installed
2024-11-27 20:04:47,724:INFO:             fastapi: Not installed
2024-11-27 20:04:47,724:INFO:             uvicorn: Not installed
2024-11-27 20:04:47,724:INFO:              m2cgen: Not installed
2024-11-27 20:04:47,724:INFO:           evidently: Not installed
2024-11-27 20:04:47,724:INFO:               fugue: Not installed
2024-11-27 20:04:47,724:INFO:           streamlit: 1.38.0
2024-11-27 20:04:47,724:INFO:             prophet: Not installed
2024-11-27 20:04:47,724:INFO:None
2024-11-27 20:04:47,724:INFO:Set up data.
2024-11-27 20:04:47,741:INFO:Set up folding strategy.
2024-11-27 20:04:47,741:INFO:Set up train/test split.
2024-11-27 20:04:47,744:INFO:Set up index.
2024-11-27 20:04:47,744:INFO:Assigning column types.
2024-11-27 20:04:47,744:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-27 20:04:47,790:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-27 20:04:47,790:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-27 20:04:47,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:04:47,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:04:47,847:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-27 20:04:47,847:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-27 20:04:47,874:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:04:47,874:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:04:47,874:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-27 20:04:47,908:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-27 20:04:47,924:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:04:47,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:04:47,967:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-27 20:04:47,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:04:47,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:04:47,988:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-27 20:04:48,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:04:48,044:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:04:48,099:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:04:48,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:04:48,101:INFO:Preparing preprocessing pipeline...
2024-11-27 20:04:48,101:INFO:Set up simple imputation.
2024-11-27 20:04:48,103:INFO:Set up encoding of ordinal features.
2024-11-27 20:04:48,104:INFO:Set up encoding of categorical features.
2024-11-27 20:04:48,156:INFO:Finished creating preprocessing pipeline.
2024-11-27 20:04:48,172:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-11-27 20:04:48,172:INFO:Creating final display dataframe.
2024-11-27 20:04:48,324:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              5e16
2024-11-27 20:04:48,408:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:04:48,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:04:48,458:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:04:48,458:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:04:48,458:INFO:setup() successfully completed in 0.76s...............
2024-11-27 20:04:48,458:INFO:Initializing compare_models()
2024-11-27 20:04:48,470:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-11-27 20:04:48,470:INFO:Checking exceptions
2024-11-27 20:04:48,472:INFO:Preparing display monitor
2024-11-27 20:04:48,476:INFO:Initializing Logistic Regression
2024-11-27 20:04:48,476:INFO:Total runtime is 0.0 minutes
2024-11-27 20:04:48,476:INFO:SubProcess create_model() called ==================================
2024-11-27 20:04:48,476:INFO:Initializing create_model()
2024-11-27 20:04:48,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002242E81AFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:48,476:INFO:Checking exceptions
2024-11-27 20:04:48,476:INFO:Importing libraries
2024-11-27 20:04:48,477:INFO:Copying training dataset
2024-11-27 20:04:48,479:INFO:Defining folds
2024-11-27 20:04:48,479:INFO:Declaring metric variables
2024-11-27 20:04:48,480:INFO:Importing untrained model
2024-11-27 20:04:48,480:INFO:Logistic Regression Imported successfully
2024-11-27 20:04:48,481:INFO:Starting cross validation
2024-11-27 20:04:48,482:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:04:50,840:INFO:Calculating mean and std
2024-11-27 20:04:50,840:INFO:Creating metrics dataframe
2024-11-27 20:04:50,850:INFO:Uploading results into container
2024-11-27 20:04:50,850:INFO:Uploading model into container now
2024-11-27 20:04:50,851:INFO:_master_model_container: 1
2024-11-27 20:04:50,851:INFO:_display_container: 2
2024-11-27 20:04:50,852:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-27 20:04:50,852:INFO:create_model() successfully completed......................................
2024-11-27 20:04:50,923:INFO:SubProcess create_model() end ==================================
2024-11-27 20:04:50,923:INFO:Creating metrics dataframe
2024-11-27 20:04:50,923:INFO:Initializing K Neighbors Classifier
2024-11-27 20:04:50,923:INFO:Total runtime is 0.04078757365544637 minutes
2024-11-27 20:04:50,939:INFO:SubProcess create_model() called ==================================
2024-11-27 20:04:50,939:INFO:Initializing create_model()
2024-11-27 20:04:50,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002242E81AFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:50,939:INFO:Checking exceptions
2024-11-27 20:04:50,939:INFO:Importing libraries
2024-11-27 20:04:50,939:INFO:Copying training dataset
2024-11-27 20:04:50,940:INFO:Defining folds
2024-11-27 20:04:50,940:INFO:Declaring metric variables
2024-11-27 20:04:50,940:INFO:Importing untrained model
2024-11-27 20:04:50,940:INFO:K Neighbors Classifier Imported successfully
2024-11-27 20:04:50,940:INFO:Starting cross validation
2024-11-27 20:04:50,940:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:04:52,223:INFO:Calculating mean and std
2024-11-27 20:04:52,224:INFO:Creating metrics dataframe
2024-11-27 20:04:52,227:INFO:Uploading results into container
2024-11-27 20:04:52,227:INFO:Uploading model into container now
2024-11-27 20:04:52,228:INFO:_master_model_container: 2
2024-11-27 20:04:52,228:INFO:_display_container: 2
2024-11-27 20:04:52,228:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-27 20:04:52,228:INFO:create_model() successfully completed......................................
2024-11-27 20:04:52,275:INFO:SubProcess create_model() end ==================================
2024-11-27 20:04:52,275:INFO:Creating metrics dataframe
2024-11-27 20:04:52,275:INFO:Initializing Naive Bayes
2024-11-27 20:04:52,275:INFO:Total runtime is 0.06331085364023845 minutes
2024-11-27 20:04:52,275:INFO:SubProcess create_model() called ==================================
2024-11-27 20:04:52,275:INFO:Initializing create_model()
2024-11-27 20:04:52,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002242E81AFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:52,275:INFO:Checking exceptions
2024-11-27 20:04:52,275:INFO:Importing libraries
2024-11-27 20:04:52,275:INFO:Copying training dataset
2024-11-27 20:04:52,275:INFO:Defining folds
2024-11-27 20:04:52,275:INFO:Declaring metric variables
2024-11-27 20:04:52,275:INFO:Importing untrained model
2024-11-27 20:04:52,275:INFO:Naive Bayes Imported successfully
2024-11-27 20:04:52,275:INFO:Starting cross validation
2024-11-27 20:04:52,275:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:04:52,422:INFO:Calculating mean and std
2024-11-27 20:04:52,423:INFO:Creating metrics dataframe
2024-11-27 20:04:52,426:INFO:Uploading results into container
2024-11-27 20:04:52,426:INFO:Uploading model into container now
2024-11-27 20:04:52,426:INFO:_master_model_container: 3
2024-11-27 20:04:52,426:INFO:_display_container: 2
2024-11-27 20:04:52,427:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-27 20:04:52,427:INFO:create_model() successfully completed......................................
2024-11-27 20:04:52,474:INFO:SubProcess create_model() end ==================================
2024-11-27 20:04:52,474:INFO:Creating metrics dataframe
2024-11-27 20:04:52,474:INFO:Initializing Decision Tree Classifier
2024-11-27 20:04:52,474:INFO:Total runtime is 0.06663702328999838 minutes
2024-11-27 20:04:52,474:INFO:SubProcess create_model() called ==================================
2024-11-27 20:04:52,474:INFO:Initializing create_model()
2024-11-27 20:04:52,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002242E81AFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:52,474:INFO:Checking exceptions
2024-11-27 20:04:52,474:INFO:Importing libraries
2024-11-27 20:04:52,474:INFO:Copying training dataset
2024-11-27 20:04:52,474:INFO:Defining folds
2024-11-27 20:04:52,474:INFO:Declaring metric variables
2024-11-27 20:04:52,474:INFO:Importing untrained model
2024-11-27 20:04:52,474:INFO:Decision Tree Classifier Imported successfully
2024-11-27 20:04:52,474:INFO:Starting cross validation
2024-11-27 20:04:52,474:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:04:52,623:INFO:Calculating mean and std
2024-11-27 20:04:52,623:INFO:Creating metrics dataframe
2024-11-27 20:04:52,626:INFO:Uploading results into container
2024-11-27 20:04:52,626:INFO:Uploading model into container now
2024-11-27 20:04:52,627:INFO:_master_model_container: 4
2024-11-27 20:04:52,627:INFO:_display_container: 2
2024-11-27 20:04:52,627:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-27 20:04:52,627:INFO:create_model() successfully completed......................................
2024-11-27 20:04:52,674:INFO:SubProcess create_model() end ==================================
2024-11-27 20:04:52,674:INFO:Creating metrics dataframe
2024-11-27 20:04:52,674:INFO:Initializing SVM - Linear Kernel
2024-11-27 20:04:52,674:INFO:Total runtime is 0.06996900637944539 minutes
2024-11-27 20:04:52,674:INFO:SubProcess create_model() called ==================================
2024-11-27 20:04:52,674:INFO:Initializing create_model()
2024-11-27 20:04:52,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002242E81AFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:52,674:INFO:Checking exceptions
2024-11-27 20:04:52,674:INFO:Importing libraries
2024-11-27 20:04:52,674:INFO:Copying training dataset
2024-11-27 20:04:52,674:INFO:Defining folds
2024-11-27 20:04:52,674:INFO:Declaring metric variables
2024-11-27 20:04:52,674:INFO:Importing untrained model
2024-11-27 20:04:52,674:INFO:SVM - Linear Kernel Imported successfully
2024-11-27 20:04:52,674:INFO:Starting cross validation
2024-11-27 20:04:52,674:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:04:52,791:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:04:52,791:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:04:52,823:INFO:Calculating mean and std
2024-11-27 20:04:52,824:INFO:Creating metrics dataframe
2024-11-27 20:04:52,827:INFO:Uploading results into container
2024-11-27 20:04:52,828:INFO:Uploading model into container now
2024-11-27 20:04:52,828:INFO:_master_model_container: 5
2024-11-27 20:04:52,828:INFO:_display_container: 2
2024-11-27 20:04:52,828:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-27 20:04:52,828:INFO:create_model() successfully completed......................................
2024-11-27 20:04:52,875:INFO:SubProcess create_model() end ==================================
2024-11-27 20:04:52,875:INFO:Creating metrics dataframe
2024-11-27 20:04:52,875:INFO:Initializing Ridge Classifier
2024-11-27 20:04:52,875:INFO:Total runtime is 0.0733104944229126 minutes
2024-11-27 20:04:52,875:INFO:SubProcess create_model() called ==================================
2024-11-27 20:04:52,875:INFO:Initializing create_model()
2024-11-27 20:04:52,875:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002242E81AFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:52,875:INFO:Checking exceptions
2024-11-27 20:04:52,875:INFO:Importing libraries
2024-11-27 20:04:52,875:INFO:Copying training dataset
2024-11-27 20:04:52,875:INFO:Defining folds
2024-11-27 20:04:52,875:INFO:Declaring metric variables
2024-11-27 20:04:52,875:INFO:Importing untrained model
2024-11-27 20:04:52,875:INFO:Ridge Classifier Imported successfully
2024-11-27 20:04:52,875:INFO:Starting cross validation
2024-11-27 20:04:52,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:04:53,022:INFO:Calculating mean and std
2024-11-27 20:04:53,023:INFO:Creating metrics dataframe
2024-11-27 20:04:53,026:INFO:Uploading results into container
2024-11-27 20:04:53,026:INFO:Uploading model into container now
2024-11-27 20:04:53,026:INFO:_master_model_container: 6
2024-11-27 20:04:53,026:INFO:_display_container: 2
2024-11-27 20:04:53,027:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-27 20:04:53,027:INFO:create_model() successfully completed......................................
2024-11-27 20:04:53,074:INFO:SubProcess create_model() end ==================================
2024-11-27 20:04:53,074:INFO:Creating metrics dataframe
2024-11-27 20:04:53,074:INFO:Initializing Random Forest Classifier
2024-11-27 20:04:53,074:INFO:Total runtime is 0.07663586139678955 minutes
2024-11-27 20:04:53,074:INFO:SubProcess create_model() called ==================================
2024-11-27 20:04:53,074:INFO:Initializing create_model()
2024-11-27 20:04:53,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002242E81AFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:53,074:INFO:Checking exceptions
2024-11-27 20:04:53,074:INFO:Importing libraries
2024-11-27 20:04:53,074:INFO:Copying training dataset
2024-11-27 20:04:53,074:INFO:Defining folds
2024-11-27 20:04:53,074:INFO:Declaring metric variables
2024-11-27 20:04:53,074:INFO:Importing untrained model
2024-11-27 20:04:53,074:INFO:Random Forest Classifier Imported successfully
2024-11-27 20:04:53,074:INFO:Starting cross validation
2024-11-27 20:04:53,074:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:04:53,440:INFO:Calculating mean and std
2024-11-27 20:04:53,441:INFO:Creating metrics dataframe
2024-11-27 20:04:53,443:INFO:Uploading results into container
2024-11-27 20:04:53,443:INFO:Uploading model into container now
2024-11-27 20:04:53,444:INFO:_master_model_container: 7
2024-11-27 20:04:53,444:INFO:_display_container: 2
2024-11-27 20:04:53,444:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-27 20:04:53,444:INFO:create_model() successfully completed......................................
2024-11-27 20:04:53,491:INFO:SubProcess create_model() end ==================================
2024-11-27 20:04:53,491:INFO:Creating metrics dataframe
2024-11-27 20:04:53,491:INFO:Initializing Quadratic Discriminant Analysis
2024-11-27 20:04:53,491:INFO:Total runtime is 0.08358661731084187 minutes
2024-11-27 20:04:53,491:INFO:SubProcess create_model() called ==================================
2024-11-27 20:04:53,491:INFO:Initializing create_model()
2024-11-27 20:04:53,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002242E81AFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:53,491:INFO:Checking exceptions
2024-11-27 20:04:53,491:INFO:Importing libraries
2024-11-27 20:04:53,491:INFO:Copying training dataset
2024-11-27 20:04:53,491:INFO:Defining folds
2024-11-27 20:04:53,491:INFO:Declaring metric variables
2024-11-27 20:04:53,491:INFO:Importing untrained model
2024-11-27 20:04:53,491:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-27 20:04:53,491:INFO:Starting cross validation
2024-11-27 20:04:53,491:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:04:53,557:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:04:53,575:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:04:53,575:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:04:53,575:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:04:53,575:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:04:53,575:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:04:53,575:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:04:53,575:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:04:53,575:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:04:53,575:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:04:53,640:INFO:Calculating mean and std
2024-11-27 20:04:53,640:INFO:Creating metrics dataframe
2024-11-27 20:04:53,643:INFO:Uploading results into container
2024-11-27 20:04:53,643:INFO:Uploading model into container now
2024-11-27 20:04:53,643:INFO:_master_model_container: 8
2024-11-27 20:04:53,643:INFO:_display_container: 2
2024-11-27 20:04:53,644:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-27 20:04:53,644:INFO:create_model() successfully completed......................................
2024-11-27 20:04:53,691:INFO:SubProcess create_model() end ==================================
2024-11-27 20:04:53,691:INFO:Creating metrics dataframe
2024-11-27 20:04:53,691:INFO:Initializing Ada Boost Classifier
2024-11-27 20:04:53,691:INFO:Total runtime is 0.08692103226979572 minutes
2024-11-27 20:04:53,691:INFO:SubProcess create_model() called ==================================
2024-11-27 20:04:53,691:INFO:Initializing create_model()
2024-11-27 20:04:53,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002242E81AFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:53,691:INFO:Checking exceptions
2024-11-27 20:04:53,691:INFO:Importing libraries
2024-11-27 20:04:53,691:INFO:Copying training dataset
2024-11-27 20:04:53,691:INFO:Defining folds
2024-11-27 20:04:53,691:INFO:Declaring metric variables
2024-11-27 20:04:53,691:INFO:Importing untrained model
2024-11-27 20:04:53,691:INFO:Ada Boost Classifier Imported successfully
2024-11-27 20:04:53,691:INFO:Starting cross validation
2024-11-27 20:04:53,691:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:04:53,757:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:04:53,757:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:04:53,757:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:04:53,757:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:04:53,773:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:04:53,773:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:04:53,773:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:04:53,773:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:04:53,773:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:04:53,773:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:04:53,957:INFO:Calculating mean and std
2024-11-27 20:04:53,957:INFO:Creating metrics dataframe
2024-11-27 20:04:53,960:INFO:Uploading results into container
2024-11-27 20:04:53,960:INFO:Uploading model into container now
2024-11-27 20:04:53,961:INFO:_master_model_container: 9
2024-11-27 20:04:53,961:INFO:_display_container: 2
2024-11-27 20:04:53,961:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-27 20:04:53,961:INFO:create_model() successfully completed......................................
2024-11-27 20:04:54,008:INFO:SubProcess create_model() end ==================================
2024-11-27 20:04:54,008:INFO:Creating metrics dataframe
2024-11-27 20:04:54,008:INFO:Initializing Gradient Boosting Classifier
2024-11-27 20:04:54,008:INFO:Total runtime is 0.09220151106516519 minutes
2024-11-27 20:04:54,008:INFO:SubProcess create_model() called ==================================
2024-11-27 20:04:54,008:INFO:Initializing create_model()
2024-11-27 20:04:54,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002242E81AFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:54,008:INFO:Checking exceptions
2024-11-27 20:04:54,008:INFO:Importing libraries
2024-11-27 20:04:54,008:INFO:Copying training dataset
2024-11-27 20:04:54,008:INFO:Defining folds
2024-11-27 20:04:54,008:INFO:Declaring metric variables
2024-11-27 20:04:54,008:INFO:Importing untrained model
2024-11-27 20:04:54,008:INFO:Gradient Boosting Classifier Imported successfully
2024-11-27 20:04:54,008:INFO:Starting cross validation
2024-11-27 20:04:54,008:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:04:54,322:INFO:Calculating mean and std
2024-11-27 20:04:54,323:INFO:Creating metrics dataframe
2024-11-27 20:04:54,326:INFO:Uploading results into container
2024-11-27 20:04:54,326:INFO:Uploading model into container now
2024-11-27 20:04:54,326:INFO:_master_model_container: 10
2024-11-27 20:04:54,326:INFO:_display_container: 2
2024-11-27 20:04:54,327:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-27 20:04:54,327:INFO:create_model() successfully completed......................................
2024-11-27 20:04:54,374:INFO:SubProcess create_model() end ==================================
2024-11-27 20:04:54,374:INFO:Creating metrics dataframe
2024-11-27 20:04:54,374:INFO:Initializing Linear Discriminant Analysis
2024-11-27 20:04:54,374:INFO:Total runtime is 0.09830335776011148 minutes
2024-11-27 20:04:54,374:INFO:SubProcess create_model() called ==================================
2024-11-27 20:04:54,374:INFO:Initializing create_model()
2024-11-27 20:04:54,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002242E81AFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:54,374:INFO:Checking exceptions
2024-11-27 20:04:54,374:INFO:Importing libraries
2024-11-27 20:04:54,374:INFO:Copying training dataset
2024-11-27 20:04:54,374:INFO:Defining folds
2024-11-27 20:04:54,374:INFO:Declaring metric variables
2024-11-27 20:04:54,374:INFO:Importing untrained model
2024-11-27 20:04:54,374:INFO:Linear Discriminant Analysis Imported successfully
2024-11-27 20:04:54,374:INFO:Starting cross validation
2024-11-27 20:04:54,374:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:04:54,523:INFO:Calculating mean and std
2024-11-27 20:04:54,524:INFO:Creating metrics dataframe
2024-11-27 20:04:54,528:INFO:Uploading results into container
2024-11-27 20:04:54,528:INFO:Uploading model into container now
2024-11-27 20:04:54,528:INFO:_master_model_container: 11
2024-11-27 20:04:54,528:INFO:_display_container: 2
2024-11-27 20:04:54,528:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-27 20:04:54,528:INFO:create_model() successfully completed......................................
2024-11-27 20:04:54,574:INFO:SubProcess create_model() end ==================================
2024-11-27 20:04:54,574:INFO:Creating metrics dataframe
2024-11-27 20:04:54,574:INFO:Initializing Extra Trees Classifier
2024-11-27 20:04:54,574:INFO:Total runtime is 0.10163476864496866 minutes
2024-11-27 20:04:54,574:INFO:SubProcess create_model() called ==================================
2024-11-27 20:04:54,574:INFO:Initializing create_model()
2024-11-27 20:04:54,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002242E81AFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:54,574:INFO:Checking exceptions
2024-11-27 20:04:54,574:INFO:Importing libraries
2024-11-27 20:04:54,574:INFO:Copying training dataset
2024-11-27 20:04:54,574:INFO:Defining folds
2024-11-27 20:04:54,574:INFO:Declaring metric variables
2024-11-27 20:04:54,574:INFO:Importing untrained model
2024-11-27 20:04:54,574:INFO:Extra Trees Classifier Imported successfully
2024-11-27 20:04:54,574:INFO:Starting cross validation
2024-11-27 20:04:54,574:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:04:54,939:INFO:Calculating mean and std
2024-11-27 20:04:54,940:INFO:Creating metrics dataframe
2024-11-27 20:04:54,942:INFO:Uploading results into container
2024-11-27 20:04:54,942:INFO:Uploading model into container now
2024-11-27 20:04:54,943:INFO:_master_model_container: 12
2024-11-27 20:04:54,943:INFO:_display_container: 2
2024-11-27 20:04:54,943:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-27 20:04:54,943:INFO:create_model() successfully completed......................................
2024-11-27 20:04:54,991:INFO:SubProcess create_model() end ==================================
2024-11-27 20:04:54,991:INFO:Creating metrics dataframe
2024-11-27 20:04:54,991:INFO:Initializing Light Gradient Boosting Machine
2024-11-27 20:04:54,991:INFO:Total runtime is 0.10858935912450154 minutes
2024-11-27 20:04:54,991:INFO:SubProcess create_model() called ==================================
2024-11-27 20:04:54,991:INFO:Initializing create_model()
2024-11-27 20:04:54,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002242E81AFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:54,991:INFO:Checking exceptions
2024-11-27 20:04:54,991:INFO:Importing libraries
2024-11-27 20:04:54,991:INFO:Copying training dataset
2024-11-27 20:04:54,991:INFO:Defining folds
2024-11-27 20:04:54,991:INFO:Declaring metric variables
2024-11-27 20:04:54,991:INFO:Importing untrained model
2024-11-27 20:04:54,991:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-27 20:04:54,991:INFO:Starting cross validation
2024-11-27 20:04:54,991:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:04:56,473:INFO:Calculating mean and std
2024-11-27 20:04:56,473:INFO:Creating metrics dataframe
2024-11-27 20:04:56,478:INFO:Uploading results into container
2024-11-27 20:04:56,478:INFO:Uploading model into container now
2024-11-27 20:04:56,479:INFO:_master_model_container: 13
2024-11-27 20:04:56,479:INFO:_display_container: 2
2024-11-27 20:04:56,479:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-27 20:04:56,479:INFO:create_model() successfully completed......................................
2024-11-27 20:04:56,540:INFO:SubProcess create_model() end ==================================
2024-11-27 20:04:56,540:INFO:Creating metrics dataframe
2024-11-27 20:04:56,540:INFO:Initializing Dummy Classifier
2024-11-27 20:04:56,540:INFO:Total runtime is 0.13439961274464926 minutes
2024-11-27 20:04:56,540:INFO:SubProcess create_model() called ==================================
2024-11-27 20:04:56,540:INFO:Initializing create_model()
2024-11-27 20:04:56,540:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002242E81AFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:56,540:INFO:Checking exceptions
2024-11-27 20:04:56,540:INFO:Importing libraries
2024-11-27 20:04:56,540:INFO:Copying training dataset
2024-11-27 20:04:56,540:INFO:Defining folds
2024-11-27 20:04:56,540:INFO:Declaring metric variables
2024-11-27 20:04:56,540:INFO:Importing untrained model
2024-11-27 20:04:56,540:INFO:Dummy Classifier Imported successfully
2024-11-27 20:04:56,540:INFO:Starting cross validation
2024-11-27 20:04:56,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:04:56,640:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:04:56,640:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:04:56,657:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:04:56,657:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:04:56,657:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:04:56,657:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:04:56,657:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:04:56,657:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:04:56,657:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:04:56,657:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:04:56,689:INFO:Calculating mean and std
2024-11-27 20:04:56,690:INFO:Creating metrics dataframe
2024-11-27 20:04:56,692:INFO:Uploading results into container
2024-11-27 20:04:56,693:INFO:Uploading model into container now
2024-11-27 20:04:56,693:INFO:_master_model_container: 14
2024-11-27 20:04:56,693:INFO:_display_container: 2
2024-11-27 20:04:56,693:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-11-27 20:04:56,693:INFO:create_model() successfully completed......................................
2024-11-27 20:04:56,741:INFO:SubProcess create_model() end ==================================
2024-11-27 20:04:56,741:INFO:Creating metrics dataframe
2024-11-27 20:04:56,741:INFO:Initializing create_model()
2024-11-27 20:04:56,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:56,741:INFO:Checking exceptions
2024-11-27 20:04:56,741:INFO:Importing libraries
2024-11-27 20:04:56,741:INFO:Copying training dataset
2024-11-27 20:04:56,741:INFO:Defining folds
2024-11-27 20:04:56,741:INFO:Declaring metric variables
2024-11-27 20:04:56,741:INFO:Importing untrained model
2024-11-27 20:04:56,741:INFO:Declaring custom model
2024-11-27 20:04:56,741:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-27 20:04:56,741:INFO:Cross validation set to False
2024-11-27 20:04:56,741:INFO:Fitting Model
2024-11-27 20:04:56,791:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-11-27 20:04:56,791:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000126 seconds.
2024-11-27 20:04:56,791:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-11-27 20:04:56,791:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-11-27 20:04:56,791:INFO:[LightGBM] [Info] Total Bins 191
2024-11-27 20:04:56,791:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-11-27 20:04:56,791:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-11-27 20:04:56,791:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:04:56,807:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-27 20:04:56,807:INFO:create_model() successfully completed......................................
2024-11-27 20:04:56,883:INFO:Initializing create_model()
2024-11-27 20:04:56,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:56,883:INFO:Checking exceptions
2024-11-27 20:04:56,884:INFO:Importing libraries
2024-11-27 20:04:56,884:INFO:Copying training dataset
2024-11-27 20:04:56,887:INFO:Defining folds
2024-11-27 20:04:56,887:INFO:Declaring metric variables
2024-11-27 20:04:56,888:INFO:Importing untrained model
2024-11-27 20:04:56,888:INFO:Declaring custom model
2024-11-27 20:04:56,888:INFO:Gradient Boosting Classifier Imported successfully
2024-11-27 20:04:56,890:INFO:Cross validation set to False
2024-11-27 20:04:56,890:INFO:Fitting Model
2024-11-27 20:04:57,023:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-27 20:04:57,023:INFO:create_model() successfully completed......................................
2024-11-27 20:04:57,074:INFO:Initializing create_model()
2024-11-27 20:04:57,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:57,074:INFO:Checking exceptions
2024-11-27 20:04:57,074:INFO:Importing libraries
2024-11-27 20:04:57,074:INFO:Copying training dataset
2024-11-27 20:04:57,074:INFO:Defining folds
2024-11-27 20:04:57,074:INFO:Declaring metric variables
2024-11-27 20:04:57,074:INFO:Importing untrained model
2024-11-27 20:04:57,074:INFO:Declaring custom model
2024-11-27 20:04:57,074:INFO:Random Forest Classifier Imported successfully
2024-11-27 20:04:57,074:INFO:Cross validation set to False
2024-11-27 20:04:57,074:INFO:Fitting Model
2024-11-27 20:04:57,222:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-27 20:04:57,222:INFO:create_model() successfully completed......................................
2024-11-27 20:04:57,272:INFO:Initializing create_model()
2024-11-27 20:04:57,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:57,273:INFO:Checking exceptions
2024-11-27 20:04:57,273:INFO:Importing libraries
2024-11-27 20:04:57,273:INFO:Copying training dataset
2024-11-27 20:04:57,277:INFO:Defining folds
2024-11-27 20:04:57,277:INFO:Declaring metric variables
2024-11-27 20:04:57,277:INFO:Importing untrained model
2024-11-27 20:04:57,277:INFO:Declaring custom model
2024-11-27 20:04:57,278:INFO:Ada Boost Classifier Imported successfully
2024-11-27 20:04:57,279:INFO:Cross validation set to False
2024-11-27 20:04:57,279:INFO:Fitting Model
2024-11-27 20:04:57,312:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:04:57,373:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-27 20:04:57,373:INFO:create_model() successfully completed......................................
2024-11-27 20:04:57,423:INFO:Initializing create_model()
2024-11-27 20:04:57,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:57,424:INFO:Checking exceptions
2024-11-27 20:04:57,424:INFO:Importing libraries
2024-11-27 20:04:57,424:INFO:Copying training dataset
2024-11-27 20:04:57,424:INFO:Defining folds
2024-11-27 20:04:57,424:INFO:Declaring metric variables
2024-11-27 20:04:57,424:INFO:Importing untrained model
2024-11-27 20:04:57,424:INFO:Declaring custom model
2024-11-27 20:04:57,424:INFO:Logistic Regression Imported successfully
2024-11-27 20:04:57,424:INFO:Cross validation set to False
2024-11-27 20:04:57,424:INFO:Fitting Model
2024-11-27 20:04:57,474:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-27 20:04:57,474:INFO:create_model() successfully completed......................................
2024-11-27 20:04:57,539:INFO:Initializing create_model()
2024-11-27 20:04:57,539:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:57,539:INFO:Checking exceptions
2024-11-27 20:04:57,539:INFO:Importing libraries
2024-11-27 20:04:57,539:INFO:Copying training dataset
2024-11-27 20:04:57,542:INFO:Defining folds
2024-11-27 20:04:57,542:INFO:Declaring metric variables
2024-11-27 20:04:57,543:INFO:Importing untrained model
2024-11-27 20:04:57,543:INFO:Declaring custom model
2024-11-27 20:04:57,543:INFO:Extra Trees Classifier Imported successfully
2024-11-27 20:04:57,544:INFO:Cross validation set to False
2024-11-27 20:04:57,544:INFO:Fitting Model
2024-11-27 20:04:57,657:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-27 20:04:57,657:INFO:create_model() successfully completed......................................
2024-11-27 20:04:57,707:INFO:Initializing create_model()
2024-11-27 20:04:57,707:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:57,707:INFO:Checking exceptions
2024-11-27 20:04:57,707:INFO:Importing libraries
2024-11-27 20:04:57,707:INFO:Copying training dataset
2024-11-27 20:04:57,707:INFO:Defining folds
2024-11-27 20:04:57,707:INFO:Declaring metric variables
2024-11-27 20:04:57,707:INFO:Importing untrained model
2024-11-27 20:04:57,707:INFO:Declaring custom model
2024-11-27 20:04:57,707:INFO:Ridge Classifier Imported successfully
2024-11-27 20:04:57,707:INFO:Cross validation set to False
2024-11-27 20:04:57,707:INFO:Fitting Model
2024-11-27 20:04:57,740:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-27 20:04:57,740:INFO:create_model() successfully completed......................................
2024-11-27 20:04:57,802:INFO:Initializing create_model()
2024-11-27 20:04:57,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:57,802:INFO:Checking exceptions
2024-11-27 20:04:57,802:INFO:Importing libraries
2024-11-27 20:04:57,802:INFO:Copying training dataset
2024-11-27 20:04:57,805:INFO:Defining folds
2024-11-27 20:04:57,805:INFO:Declaring metric variables
2024-11-27 20:04:57,805:INFO:Importing untrained model
2024-11-27 20:04:57,805:INFO:Declaring custom model
2024-11-27 20:04:57,805:INFO:Linear Discriminant Analysis Imported successfully
2024-11-27 20:04:57,807:INFO:Cross validation set to False
2024-11-27 20:04:57,807:INFO:Fitting Model
2024-11-27 20:04:57,841:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-27 20:04:57,841:INFO:create_model() successfully completed......................................
2024-11-27 20:04:57,890:INFO:Initializing create_model()
2024-11-27 20:04:57,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:57,890:INFO:Checking exceptions
2024-11-27 20:04:57,890:INFO:Importing libraries
2024-11-27 20:04:57,890:INFO:Copying training dataset
2024-11-27 20:04:57,890:INFO:Defining folds
2024-11-27 20:04:57,890:INFO:Declaring metric variables
2024-11-27 20:04:57,890:INFO:Importing untrained model
2024-11-27 20:04:57,890:INFO:Declaring custom model
2024-11-27 20:04:57,890:INFO:Naive Bayes Imported successfully
2024-11-27 20:04:57,890:INFO:Cross validation set to False
2024-11-27 20:04:57,890:INFO:Fitting Model
2024-11-27 20:04:57,923:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-27 20:04:57,923:INFO:create_model() successfully completed......................................
2024-11-27 20:04:57,980:INFO:Initializing create_model()
2024-11-27 20:04:57,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:57,980:INFO:Checking exceptions
2024-11-27 20:04:57,980:INFO:Importing libraries
2024-11-27 20:04:57,980:INFO:Copying training dataset
2024-11-27 20:04:57,983:INFO:Defining folds
2024-11-27 20:04:57,983:INFO:Declaring metric variables
2024-11-27 20:04:57,983:INFO:Importing untrained model
2024-11-27 20:04:57,983:INFO:Declaring custom model
2024-11-27 20:04:57,983:INFO:Decision Tree Classifier Imported successfully
2024-11-27 20:04:57,984:INFO:Cross validation set to False
2024-11-27 20:04:57,984:INFO:Fitting Model
2024-11-27 20:04:58,020:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-27 20:04:58,020:INFO:create_model() successfully completed......................................
2024-11-27 20:04:58,057:INFO:Initializing create_model()
2024-11-27 20:04:58,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:58,057:INFO:Checking exceptions
2024-11-27 20:04:58,057:INFO:Importing libraries
2024-11-27 20:04:58,057:INFO:Copying training dataset
2024-11-27 20:04:58,073:INFO:Defining folds
2024-11-27 20:04:58,073:INFO:Declaring metric variables
2024-11-27 20:04:58,074:INFO:Importing untrained model
2024-11-27 20:04:58,074:INFO:Declaring custom model
2024-11-27 20:04:58,074:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-27 20:04:58,074:INFO:Cross validation set to False
2024-11-27 20:04:58,074:INFO:Fitting Model
2024-11-27 20:04:58,107:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:04:58,107:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-27 20:04:58,107:INFO:create_model() successfully completed......................................
2024-11-27 20:04:58,160:INFO:Initializing create_model()
2024-11-27 20:04:58,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:58,160:INFO:Checking exceptions
2024-11-27 20:04:58,160:INFO:Importing libraries
2024-11-27 20:04:58,160:INFO:Copying training dataset
2024-11-27 20:04:58,163:INFO:Defining folds
2024-11-27 20:04:58,163:INFO:Declaring metric variables
2024-11-27 20:04:58,163:INFO:Importing untrained model
2024-11-27 20:04:58,163:INFO:Declaring custom model
2024-11-27 20:04:58,163:INFO:K Neighbors Classifier Imported successfully
2024-11-27 20:04:58,164:INFO:Cross validation set to False
2024-11-27 20:04:58,164:INFO:Fitting Model
2024-11-27 20:04:58,199:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-27 20:04:58,199:INFO:create_model() successfully completed......................................
2024-11-27 20:04:58,240:INFO:Initializing create_model()
2024-11-27 20:04:58,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:58,240:INFO:Checking exceptions
2024-11-27 20:04:58,240:INFO:Importing libraries
2024-11-27 20:04:58,240:INFO:Copying training dataset
2024-11-27 20:04:58,240:INFO:Defining folds
2024-11-27 20:04:58,240:INFO:Declaring metric variables
2024-11-27 20:04:58,240:INFO:Importing untrained model
2024-11-27 20:04:58,240:INFO:Declaring custom model
2024-11-27 20:04:58,240:INFO:SVM - Linear Kernel Imported successfully
2024-11-27 20:04:58,240:INFO:Cross validation set to False
2024-11-27 20:04:58,240:INFO:Fitting Model
2024-11-27 20:04:58,289:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-27 20:04:58,289:INFO:create_model() successfully completed......................................
2024-11-27 20:04:58,340:INFO:Initializing create_model()
2024-11-27 20:04:58,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002242E81A940>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:04:58,340:INFO:Checking exceptions
2024-11-27 20:04:58,340:INFO:Importing libraries
2024-11-27 20:04:58,341:INFO:Copying training dataset
2024-11-27 20:04:58,343:INFO:Defining folds
2024-11-27 20:04:58,343:INFO:Declaring metric variables
2024-11-27 20:04:58,343:INFO:Importing untrained model
2024-11-27 20:04:58,343:INFO:Declaring custom model
2024-11-27 20:04:58,343:INFO:Dummy Classifier Imported successfully
2024-11-27 20:04:58,344:INFO:Cross validation set to False
2024-11-27 20:04:58,344:INFO:Fitting Model
2024-11-27 20:04:58,377:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-11-27 20:04:58,377:INFO:create_model() successfully completed......................................
2024-11-27 20:04:58,433:INFO:_master_model_container: 14
2024-11-27 20:04:58,433:INFO:_display_container: 2
2024-11-27 20:04:58,435:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')]
2024-11-27 20:04:58,435:INFO:compare_models() successfully completed......................................
2024-11-27 20:11:00,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:11:00,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:11:00,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:11:00,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:12:27,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:12:27,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:12:27,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:12:27,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:13:56,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:13:56,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:13:56,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:13:56,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:15:06,025:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:15:06,025:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:15:06,025:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:15:06,025:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:15:14,425:INFO:PyCaret ClassificationExperiment
2024-11-27 20:15:14,426:INFO:Logging name: clf-default-name
2024-11-27 20:15:14,426:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-27 20:15:14,426:INFO:version 3.3.2
2024-11-27 20:15:14,426:INFO:Initializing setup()
2024-11-27 20:15:14,426:INFO:self.USI: 1456
2024-11-27 20:15:14,426:INFO:self._variable_keys: {'n_jobs_param', '_available_plots', 'target_param', 'X', 'USI', 'pipeline', 'data', 'fold_groups_param', 'html_param', '_ml_usecase', 'y_test', 'seed', 'log_plots_param', 'memory', 'fold_shuffle_param', 'y', 'exp_id', 'gpu_param', 'logging_param', 'X_train', 'exp_name_log', 'gpu_n_jobs_param', 'y_train', 'idx', 'fix_imbalance', 'X_test', 'fold_generator', 'is_multiclass'}
2024-11-27 20:15:14,426:INFO:Checking environment
2024-11-27 20:15:14,426:INFO:python_version: 3.9.1
2024-11-27 20:15:14,426:INFO:python_build: ('tags/v3.9.1:1e5d33e', 'Dec  7 2020 17:08:21')
2024-11-27 20:15:14,426:INFO:machine: AMD64
2024-11-27 20:15:14,427:INFO:platform: Windows-10-10.0.18362-SP0
2024-11-27 20:15:14,428:INFO:Memory: svmem(total=16973832192, available=10304823296, percent=39.3, used=6669008896, free=10304823296)
2024-11-27 20:15:14,428:INFO:Physical Core: 6
2024-11-27 20:15:14,428:INFO:Logical Core: 12
2024-11-27 20:15:14,428:INFO:Checking libraries
2024-11-27 20:15:14,428:INFO:System:
2024-11-27 20:15:14,428:INFO:    python: 3.9.1 (tags/v3.9.1:1e5d33e, Dec  7 2020, 17:08:21) [MSC v.1927 64 bit (AMD64)]
2024-11-27 20:15:14,428:INFO:executable: c:\users\user\appdata\local\programs\python\python39\python.exe
2024-11-27 20:15:14,429:INFO:   machine: Windows-10-10.0.18362-SP0
2024-11-27 20:15:14,429:INFO:PyCaret required dependencies:
2024-11-27 20:15:14,443:INFO:                 pip: 24.3.1
2024-11-27 20:15:14,443:INFO:          setuptools: 75.6.0
2024-11-27 20:15:14,443:INFO:             pycaret: 3.3.2
2024-11-27 20:15:14,443:INFO:             IPython: 8.18.1
2024-11-27 20:15:14,443:INFO:          ipywidgets: 8.1.5
2024-11-27 20:15:14,443:INFO:                tqdm: 4.67.1
2024-11-27 20:15:14,443:INFO:               numpy: 1.21.6
2024-11-27 20:15:14,443:INFO:              pandas: 1.3.5
2024-11-27 20:15:14,443:INFO:              jinja2: 3.1.4
2024-11-27 20:15:14,443:INFO:               scipy: 1.7.3
2024-11-27 20:15:14,443:INFO:              joblib: 1.3.2
2024-11-27 20:15:14,443:INFO:             sklearn: 1.4.2
2024-11-27 20:15:14,443:INFO:                pyod: 2.0.2
2024-11-27 20:15:14,443:INFO:            imblearn: 0.12.4
2024-11-27 20:15:14,443:INFO:   category_encoders: 2.6.4
2024-11-27 20:15:14,443:INFO:            lightgbm: 4.5.0
2024-11-27 20:15:14,443:INFO:               numba: 0.58.0
2024-11-27 20:15:14,443:INFO:            requests: 2.32.3
2024-11-27 20:15:14,443:INFO:          matplotlib: 3.7.5
2024-11-27 20:15:14,443:INFO:          scikitplot: 0.3.7
2024-11-27 20:15:14,443:INFO:         yellowbrick: 1.5
2024-11-27 20:15:14,443:INFO:              plotly: 5.24.1
2024-11-27 20:15:14,443:INFO:    plotly-resampler: Not installed
2024-11-27 20:15:14,443:INFO:             kaleido: 0.2.1
2024-11-27 20:15:14,443:INFO:           schemdraw: 0.15
2024-11-27 20:15:14,443:INFO:         statsmodels: 0.14.1
2024-11-27 20:15:14,443:INFO:              sktime: 0.26.0
2024-11-27 20:15:14,443:INFO:               tbats: 1.1.3
2024-11-27 20:15:14,443:INFO:            pmdarima: 2.0.4
2024-11-27 20:15:14,443:INFO:              psutil: 6.1.0
2024-11-27 20:15:14,443:INFO:          markupsafe: 3.0.2
2024-11-27 20:15:14,443:INFO:             pickle5: Not installed
2024-11-27 20:15:14,443:INFO:         cloudpickle: 3.1.0
2024-11-27 20:15:14,443:INFO:         deprecation: 2.1.0
2024-11-27 20:15:14,443:INFO:              xxhash: 3.5.0
2024-11-27 20:15:14,443:INFO:           wurlitzer: Not installed
2024-11-27 20:15:14,443:INFO:PyCaret optional dependencies:
2024-11-27 20:15:14,443:INFO:                shap: Not installed
2024-11-27 20:15:14,443:INFO:           interpret: Not installed
2024-11-27 20:15:14,443:INFO:                umap: Not installed
2024-11-27 20:15:14,443:INFO:     ydata_profiling: Not installed
2024-11-27 20:15:14,443:INFO:  explainerdashboard: Not installed
2024-11-27 20:15:14,443:INFO:             autoviz: Not installed
2024-11-27 20:15:14,443:INFO:           fairlearn: Not installed
2024-11-27 20:15:14,443:INFO:          deepchecks: Not installed
2024-11-27 20:15:14,443:INFO:             xgboost: Not installed
2024-11-27 20:15:14,443:INFO:            catboost: Not installed
2024-11-27 20:15:14,443:INFO:              kmodes: Not installed
2024-11-27 20:15:14,443:INFO:             mlxtend: Not installed
2024-11-27 20:15:14,443:INFO:       statsforecast: Not installed
2024-11-27 20:15:14,443:INFO:        tune_sklearn: Not installed
2024-11-27 20:15:14,443:INFO:                 ray: Not installed
2024-11-27 20:15:14,443:INFO:            hyperopt: Not installed
2024-11-27 20:15:14,443:INFO:              optuna: 4.1.0
2024-11-27 20:15:14,443:INFO:               skopt: Not installed
2024-11-27 20:15:14,443:INFO:              mlflow: Not installed
2024-11-27 20:15:14,443:INFO:              gradio: Not installed
2024-11-27 20:15:14,443:INFO:             fastapi: Not installed
2024-11-27 20:15:14,443:INFO:             uvicorn: Not installed
2024-11-27 20:15:14,443:INFO:              m2cgen: Not installed
2024-11-27 20:15:14,443:INFO:           evidently: Not installed
2024-11-27 20:15:14,443:INFO:               fugue: Not installed
2024-11-27 20:15:14,443:INFO:           streamlit: 1.38.0
2024-11-27 20:15:14,443:INFO:             prophet: Not installed
2024-11-27 20:15:14,443:INFO:None
2024-11-27 20:15:14,443:INFO:Set up data.
2024-11-27 20:15:14,443:INFO:Set up folding strategy.
2024-11-27 20:15:14,443:INFO:Set up train/test split.
2024-11-27 20:15:14,460:INFO:Set up index.
2024-11-27 20:15:14,460:INFO:Assigning column types.
2024-11-27 20:15:14,460:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-27 20:15:14,501:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-27 20:15:14,504:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-27 20:15:14,525:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:15:14,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:15:14,557:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-27 20:15:14,557:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-27 20:15:14,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:15:14,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:15:14,573:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-27 20:15:14,608:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-27 20:15:14,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:15:14,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:15:14,676:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-27 20:15:14,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:15:14,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:15:14,696:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-27 20:15:14,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:15:14,741:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:15:14,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:15:14,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:15:14,793:INFO:Preparing preprocessing pipeline...
2024-11-27 20:15:14,793:INFO:Set up simple imputation.
2024-11-27 20:15:14,793:INFO:Set up encoding of ordinal features.
2024-11-27 20:15:14,793:INFO:Set up encoding of categorical features.
2024-11-27 20:15:14,855:INFO:Finished creating preprocessing pipeline.
2024-11-27 20:15:14,871:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-11-27 20:15:14,871:INFO:Creating final display dataframe.
2024-11-27 20:15:15,025:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              1456
2024-11-27 20:15:15,100:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:15:15,100:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:15:15,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:15:15,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:15:15,143:INFO:setup() successfully completed in 0.73s...............
2024-11-27 20:15:15,161:INFO:Initializing compare_models()
2024-11-27 20:15:15,161:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-11-27 20:15:15,161:INFO:Checking exceptions
2024-11-27 20:15:15,163:INFO:Preparing display monitor
2024-11-27 20:15:15,166:INFO:Initializing Logistic Regression
2024-11-27 20:15:15,166:INFO:Total runtime is 1.654624938964844e-05 minutes
2024-11-27 20:15:15,166:INFO:SubProcess create_model() called ==================================
2024-11-27 20:15:15,166:INFO:Initializing create_model()
2024-11-27 20:15:15,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019244ABFE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:15,166:INFO:Checking exceptions
2024-11-27 20:15:15,166:INFO:Importing libraries
2024-11-27 20:15:15,166:INFO:Copying training dataset
2024-11-27 20:15:15,169:INFO:Defining folds
2024-11-27 20:15:15,169:INFO:Declaring metric variables
2024-11-27 20:15:15,169:INFO:Importing untrained model
2024-11-27 20:15:15,169:INFO:Logistic Regression Imported successfully
2024-11-27 20:15:15,170:INFO:Starting cross validation
2024-11-27 20:15:15,171:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:15:17,441:INFO:Calculating mean and std
2024-11-27 20:15:17,441:INFO:Creating metrics dataframe
2024-11-27 20:15:17,448:INFO:Uploading results into container
2024-11-27 20:15:17,449:INFO:Uploading model into container now
2024-11-27 20:15:17,450:INFO:_master_model_container: 1
2024-11-27 20:15:17,450:INFO:_display_container: 2
2024-11-27 20:15:17,450:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-27 20:15:17,451:INFO:create_model() successfully completed......................................
2024-11-27 20:15:17,508:INFO:SubProcess create_model() end ==================================
2024-11-27 20:15:17,508:INFO:Creating metrics dataframe
2024-11-27 20:15:17,508:INFO:Initializing K Neighbors Classifier
2024-11-27 20:15:17,508:INFO:Total runtime is 0.039049561818440756 minutes
2024-11-27 20:15:17,508:INFO:SubProcess create_model() called ==================================
2024-11-27 20:15:17,508:INFO:Initializing create_model()
2024-11-27 20:15:17,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019244ABFE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:17,508:INFO:Checking exceptions
2024-11-27 20:15:17,508:INFO:Importing libraries
2024-11-27 20:15:17,508:INFO:Copying training dataset
2024-11-27 20:15:17,508:INFO:Defining folds
2024-11-27 20:15:17,508:INFO:Declaring metric variables
2024-11-27 20:15:17,508:INFO:Importing untrained model
2024-11-27 20:15:17,508:INFO:K Neighbors Classifier Imported successfully
2024-11-27 20:15:17,508:INFO:Starting cross validation
2024-11-27 20:15:17,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:15:18,790:INFO:Calculating mean and std
2024-11-27 20:15:18,792:INFO:Creating metrics dataframe
2024-11-27 20:15:18,795:INFO:Uploading results into container
2024-11-27 20:15:18,795:INFO:Uploading model into container now
2024-11-27 20:15:18,796:INFO:_master_model_container: 2
2024-11-27 20:15:18,796:INFO:_display_container: 2
2024-11-27 20:15:18,796:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-27 20:15:18,796:INFO:create_model() successfully completed......................................
2024-11-27 20:15:18,842:INFO:SubProcess create_model() end ==================================
2024-11-27 20:15:18,842:INFO:Creating metrics dataframe
2024-11-27 20:15:18,842:INFO:Initializing Naive Bayes
2024-11-27 20:15:18,842:INFO:Total runtime is 0.06128225723902385 minutes
2024-11-27 20:15:18,842:INFO:SubProcess create_model() called ==================================
2024-11-27 20:15:18,842:INFO:Initializing create_model()
2024-11-27 20:15:18,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019244ABFE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:18,842:INFO:Checking exceptions
2024-11-27 20:15:18,842:INFO:Importing libraries
2024-11-27 20:15:18,842:INFO:Copying training dataset
2024-11-27 20:15:18,842:INFO:Defining folds
2024-11-27 20:15:18,842:INFO:Declaring metric variables
2024-11-27 20:15:18,842:INFO:Importing untrained model
2024-11-27 20:15:18,842:INFO:Naive Bayes Imported successfully
2024-11-27 20:15:18,842:INFO:Starting cross validation
2024-11-27 20:15:18,858:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:15:18,990:INFO:Calculating mean and std
2024-11-27 20:15:18,991:INFO:Creating metrics dataframe
2024-11-27 20:15:18,994:INFO:Uploading results into container
2024-11-27 20:15:18,994:INFO:Uploading model into container now
2024-11-27 20:15:18,994:INFO:_master_model_container: 3
2024-11-27 20:15:18,995:INFO:_display_container: 2
2024-11-27 20:15:18,995:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-27 20:15:18,995:INFO:create_model() successfully completed......................................
2024-11-27 20:15:19,042:INFO:SubProcess create_model() end ==================================
2024-11-27 20:15:19,042:INFO:Creating metrics dataframe
2024-11-27 20:15:19,042:INFO:Initializing Decision Tree Classifier
2024-11-27 20:15:19,042:INFO:Total runtime is 0.0646205226580302 minutes
2024-11-27 20:15:19,042:INFO:SubProcess create_model() called ==================================
2024-11-27 20:15:19,042:INFO:Initializing create_model()
2024-11-27 20:15:19,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019244ABFE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:19,042:INFO:Checking exceptions
2024-11-27 20:15:19,042:INFO:Importing libraries
2024-11-27 20:15:19,042:INFO:Copying training dataset
2024-11-27 20:15:19,042:INFO:Defining folds
2024-11-27 20:15:19,042:INFO:Declaring metric variables
2024-11-27 20:15:19,042:INFO:Importing untrained model
2024-11-27 20:15:19,042:INFO:Decision Tree Classifier Imported successfully
2024-11-27 20:15:19,042:INFO:Starting cross validation
2024-11-27 20:15:19,042:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:15:19,190:INFO:Calculating mean and std
2024-11-27 20:15:19,191:INFO:Creating metrics dataframe
2024-11-27 20:15:19,194:INFO:Uploading results into container
2024-11-27 20:15:19,194:INFO:Uploading model into container now
2024-11-27 20:15:19,195:INFO:_master_model_container: 4
2024-11-27 20:15:19,195:INFO:_display_container: 2
2024-11-27 20:15:19,195:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-27 20:15:19,195:INFO:create_model() successfully completed......................................
2024-11-27 20:15:19,242:INFO:SubProcess create_model() end ==================================
2024-11-27 20:15:19,242:INFO:Creating metrics dataframe
2024-11-27 20:15:19,242:INFO:Initializing SVM - Linear Kernel
2024-11-27 20:15:19,242:INFO:Total runtime is 0.06795090039571126 minutes
2024-11-27 20:15:19,242:INFO:SubProcess create_model() called ==================================
2024-11-27 20:15:19,242:INFO:Initializing create_model()
2024-11-27 20:15:19,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019244ABFE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:19,242:INFO:Checking exceptions
2024-11-27 20:15:19,242:INFO:Importing libraries
2024-11-27 20:15:19,242:INFO:Copying training dataset
2024-11-27 20:15:19,242:INFO:Defining folds
2024-11-27 20:15:19,242:INFO:Declaring metric variables
2024-11-27 20:15:19,242:INFO:Importing untrained model
2024-11-27 20:15:19,242:INFO:SVM - Linear Kernel Imported successfully
2024-11-27 20:15:19,242:INFO:Starting cross validation
2024-11-27 20:15:19,242:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:15:19,357:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:15:19,358:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:15:19,390:INFO:Calculating mean and std
2024-11-27 20:15:19,391:INFO:Creating metrics dataframe
2024-11-27 20:15:19,394:INFO:Uploading results into container
2024-11-27 20:15:19,394:INFO:Uploading model into container now
2024-11-27 20:15:19,395:INFO:_master_model_container: 5
2024-11-27 20:15:19,395:INFO:_display_container: 2
2024-11-27 20:15:19,395:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-27 20:15:19,395:INFO:create_model() successfully completed......................................
2024-11-27 20:15:19,442:INFO:SubProcess create_model() end ==================================
2024-11-27 20:15:19,442:INFO:Creating metrics dataframe
2024-11-27 20:15:19,442:INFO:Initializing Ridge Classifier
2024-11-27 20:15:19,442:INFO:Total runtime is 0.07128989696502686 minutes
2024-11-27 20:15:19,442:INFO:SubProcess create_model() called ==================================
2024-11-27 20:15:19,442:INFO:Initializing create_model()
2024-11-27 20:15:19,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019244ABFE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:19,442:INFO:Checking exceptions
2024-11-27 20:15:19,442:INFO:Importing libraries
2024-11-27 20:15:19,442:INFO:Copying training dataset
2024-11-27 20:15:19,442:INFO:Defining folds
2024-11-27 20:15:19,442:INFO:Declaring metric variables
2024-11-27 20:15:19,442:INFO:Importing untrained model
2024-11-27 20:15:19,442:INFO:Ridge Classifier Imported successfully
2024-11-27 20:15:19,442:INFO:Starting cross validation
2024-11-27 20:15:19,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:15:19,590:INFO:Calculating mean and std
2024-11-27 20:15:19,591:INFO:Creating metrics dataframe
2024-11-27 20:15:19,594:INFO:Uploading results into container
2024-11-27 20:15:19,594:INFO:Uploading model into container now
2024-11-27 20:15:19,595:INFO:_master_model_container: 6
2024-11-27 20:15:19,595:INFO:_display_container: 2
2024-11-27 20:15:19,595:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-27 20:15:19,595:INFO:create_model() successfully completed......................................
2024-11-27 20:15:19,642:INFO:SubProcess create_model() end ==================================
2024-11-27 20:15:19,642:INFO:Creating metrics dataframe
2024-11-27 20:15:19,642:INFO:Initializing Random Forest Classifier
2024-11-27 20:15:19,642:INFO:Total runtime is 0.07462007602055867 minutes
2024-11-27 20:15:19,642:INFO:SubProcess create_model() called ==================================
2024-11-27 20:15:19,642:INFO:Initializing create_model()
2024-11-27 20:15:19,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019244ABFE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:19,642:INFO:Checking exceptions
2024-11-27 20:15:19,642:INFO:Importing libraries
2024-11-27 20:15:19,642:INFO:Copying training dataset
2024-11-27 20:15:19,642:INFO:Defining folds
2024-11-27 20:15:19,642:INFO:Declaring metric variables
2024-11-27 20:15:19,642:INFO:Importing untrained model
2024-11-27 20:15:19,642:INFO:Random Forest Classifier Imported successfully
2024-11-27 20:15:19,642:INFO:Starting cross validation
2024-11-27 20:15:19,642:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:15:20,024:INFO:Calculating mean and std
2024-11-27 20:15:20,025:INFO:Creating metrics dataframe
2024-11-27 20:15:20,027:INFO:Uploading results into container
2024-11-27 20:15:20,027:INFO:Uploading model into container now
2024-11-27 20:15:20,028:INFO:_master_model_container: 7
2024-11-27 20:15:20,028:INFO:_display_container: 2
2024-11-27 20:15:20,028:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-27 20:15:20,028:INFO:create_model() successfully completed......................................
2024-11-27 20:15:20,076:INFO:SubProcess create_model() end ==================================
2024-11-27 20:15:20,076:INFO:Creating metrics dataframe
2024-11-27 20:15:20,076:INFO:Initializing Quadratic Discriminant Analysis
2024-11-27 20:15:20,076:INFO:Total runtime is 0.08185005187988281 minutes
2024-11-27 20:15:20,076:INFO:SubProcess create_model() called ==================================
2024-11-27 20:15:20,076:INFO:Initializing create_model()
2024-11-27 20:15:20,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019244ABFE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:20,076:INFO:Checking exceptions
2024-11-27 20:15:20,076:INFO:Importing libraries
2024-11-27 20:15:20,076:INFO:Copying training dataset
2024-11-27 20:15:20,076:INFO:Defining folds
2024-11-27 20:15:20,076:INFO:Declaring metric variables
2024-11-27 20:15:20,076:INFO:Importing untrained model
2024-11-27 20:15:20,076:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-27 20:15:20,076:INFO:Starting cross validation
2024-11-27 20:15:20,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:15:20,141:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:15:20,141:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:15:20,141:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:15:20,141:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:15:20,157:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:15:20,158:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:15:20,158:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:15:20,158:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:15:20,158:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:15:20,158:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:15:20,223:INFO:Calculating mean and std
2024-11-27 20:15:20,225:INFO:Creating metrics dataframe
2024-11-27 20:15:20,225:INFO:Uploading results into container
2024-11-27 20:15:20,225:INFO:Uploading model into container now
2024-11-27 20:15:20,225:INFO:_master_model_container: 8
2024-11-27 20:15:20,225:INFO:_display_container: 2
2024-11-27 20:15:20,225:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-27 20:15:20,225:INFO:create_model() successfully completed......................................
2024-11-27 20:15:20,280:INFO:SubProcess create_model() end ==================================
2024-11-27 20:15:20,280:INFO:Creating metrics dataframe
2024-11-27 20:15:20,284:INFO:Initializing Ada Boost Classifier
2024-11-27 20:15:20,284:INFO:Total runtime is 0.0853128711382548 minutes
2024-11-27 20:15:20,285:INFO:SubProcess create_model() called ==================================
2024-11-27 20:15:20,285:INFO:Initializing create_model()
2024-11-27 20:15:20,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019244ABFE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:20,285:INFO:Checking exceptions
2024-11-27 20:15:20,285:INFO:Importing libraries
2024-11-27 20:15:20,285:INFO:Copying training dataset
2024-11-27 20:15:20,287:INFO:Defining folds
2024-11-27 20:15:20,288:INFO:Declaring metric variables
2024-11-27 20:15:20,288:INFO:Importing untrained model
2024-11-27 20:15:20,288:INFO:Ada Boost Classifier Imported successfully
2024-11-27 20:15:20,288:INFO:Starting cross validation
2024-11-27 20:15:20,289:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:15:20,341:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:15:20,341:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:15:20,357:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:15:20,358:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:15:20,358:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:15:20,358:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:15:20,358:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:15:20,358:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:15:20,358:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:15:20,358:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:15:20,541:INFO:Calculating mean and std
2024-11-27 20:15:20,541:INFO:Creating metrics dataframe
2024-11-27 20:15:20,545:INFO:Uploading results into container
2024-11-27 20:15:20,545:INFO:Uploading model into container now
2024-11-27 20:15:20,545:INFO:_master_model_container: 9
2024-11-27 20:15:20,546:INFO:_display_container: 2
2024-11-27 20:15:20,546:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-27 20:15:20,546:INFO:create_model() successfully completed......................................
2024-11-27 20:15:20,593:INFO:SubProcess create_model() end ==================================
2024-11-27 20:15:20,593:INFO:Creating metrics dataframe
2024-11-27 20:15:20,593:INFO:Initializing Gradient Boosting Classifier
2024-11-27 20:15:20,593:INFO:Total runtime is 0.09046152035395304 minutes
2024-11-27 20:15:20,593:INFO:SubProcess create_model() called ==================================
2024-11-27 20:15:20,593:INFO:Initializing create_model()
2024-11-27 20:15:20,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019244ABFE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:20,593:INFO:Checking exceptions
2024-11-27 20:15:20,593:INFO:Importing libraries
2024-11-27 20:15:20,593:INFO:Copying training dataset
2024-11-27 20:15:20,593:INFO:Defining folds
2024-11-27 20:15:20,593:INFO:Declaring metric variables
2024-11-27 20:15:20,593:INFO:Importing untrained model
2024-11-27 20:15:20,593:INFO:Gradient Boosting Classifier Imported successfully
2024-11-27 20:15:20,593:INFO:Starting cross validation
2024-11-27 20:15:20,593:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:15:20,890:INFO:Calculating mean and std
2024-11-27 20:15:20,891:INFO:Creating metrics dataframe
2024-11-27 20:15:20,894:INFO:Uploading results into container
2024-11-27 20:15:20,894:INFO:Uploading model into container now
2024-11-27 20:15:20,895:INFO:_master_model_container: 10
2024-11-27 20:15:20,895:INFO:_display_container: 2
2024-11-27 20:15:20,895:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-27 20:15:20,895:INFO:create_model() successfully completed......................................
2024-11-27 20:15:20,942:INFO:SubProcess create_model() end ==================================
2024-11-27 20:15:20,942:INFO:Creating metrics dataframe
2024-11-27 20:15:20,942:INFO:Initializing Linear Discriminant Analysis
2024-11-27 20:15:20,942:INFO:Total runtime is 0.09628145694732665 minutes
2024-11-27 20:15:20,942:INFO:SubProcess create_model() called ==================================
2024-11-27 20:15:20,942:INFO:Initializing create_model()
2024-11-27 20:15:20,942:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019244ABFE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:20,942:INFO:Checking exceptions
2024-11-27 20:15:20,942:INFO:Importing libraries
2024-11-27 20:15:20,942:INFO:Copying training dataset
2024-11-27 20:15:20,942:INFO:Defining folds
2024-11-27 20:15:20,942:INFO:Declaring metric variables
2024-11-27 20:15:20,942:INFO:Importing untrained model
2024-11-27 20:15:20,942:INFO:Linear Discriminant Analysis Imported successfully
2024-11-27 20:15:20,942:INFO:Starting cross validation
2024-11-27 20:15:20,942:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:15:21,090:INFO:Calculating mean and std
2024-11-27 20:15:21,091:INFO:Creating metrics dataframe
2024-11-27 20:15:21,094:INFO:Uploading results into container
2024-11-27 20:15:21,094:INFO:Uploading model into container now
2024-11-27 20:15:21,095:INFO:_master_model_container: 11
2024-11-27 20:15:21,095:INFO:_display_container: 2
2024-11-27 20:15:21,095:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-27 20:15:21,095:INFO:create_model() successfully completed......................................
2024-11-27 20:15:21,142:INFO:SubProcess create_model() end ==================================
2024-11-27 20:15:21,142:INFO:Creating metrics dataframe
2024-11-27 20:15:21,142:INFO:Initializing Extra Trees Classifier
2024-11-27 20:15:21,142:INFO:Total runtime is 0.09961514870325723 minutes
2024-11-27 20:15:21,142:INFO:SubProcess create_model() called ==================================
2024-11-27 20:15:21,142:INFO:Initializing create_model()
2024-11-27 20:15:21,142:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019244ABFE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:21,142:INFO:Checking exceptions
2024-11-27 20:15:21,142:INFO:Importing libraries
2024-11-27 20:15:21,142:INFO:Copying training dataset
2024-11-27 20:15:21,142:INFO:Defining folds
2024-11-27 20:15:21,142:INFO:Declaring metric variables
2024-11-27 20:15:21,142:INFO:Importing untrained model
2024-11-27 20:15:21,142:INFO:Extra Trees Classifier Imported successfully
2024-11-27 20:15:21,142:INFO:Starting cross validation
2024-11-27 20:15:21,142:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:15:21,507:INFO:Calculating mean and std
2024-11-27 20:15:21,508:INFO:Creating metrics dataframe
2024-11-27 20:15:21,510:INFO:Uploading results into container
2024-11-27 20:15:21,510:INFO:Uploading model into container now
2024-11-27 20:15:21,511:INFO:_master_model_container: 12
2024-11-27 20:15:21,511:INFO:_display_container: 2
2024-11-27 20:15:21,511:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-27 20:15:21,511:INFO:create_model() successfully completed......................................
2024-11-27 20:15:21,559:INFO:SubProcess create_model() end ==================================
2024-11-27 20:15:21,559:INFO:Creating metrics dataframe
2024-11-27 20:15:21,559:INFO:Initializing Light Gradient Boosting Machine
2024-11-27 20:15:21,559:INFO:Total runtime is 0.10657131274541218 minutes
2024-11-27 20:15:21,559:INFO:SubProcess create_model() called ==================================
2024-11-27 20:15:21,559:INFO:Initializing create_model()
2024-11-27 20:15:21,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019244ABFE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:21,559:INFO:Checking exceptions
2024-11-27 20:15:21,559:INFO:Importing libraries
2024-11-27 20:15:21,559:INFO:Copying training dataset
2024-11-27 20:15:21,559:INFO:Defining folds
2024-11-27 20:15:21,559:INFO:Declaring metric variables
2024-11-27 20:15:21,559:INFO:Importing untrained model
2024-11-27 20:15:21,559:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-27 20:15:21,559:INFO:Starting cross validation
2024-11-27 20:15:21,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:15:23,242:INFO:Calculating mean and std
2024-11-27 20:15:23,243:INFO:Creating metrics dataframe
2024-11-27 20:15:23,246:INFO:Uploading results into container
2024-11-27 20:15:23,247:INFO:Uploading model into container now
2024-11-27 20:15:23,247:INFO:_master_model_container: 13
2024-11-27 20:15:23,247:INFO:_display_container: 2
2024-11-27 20:15:23,247:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-27 20:15:23,248:INFO:create_model() successfully completed......................................
2024-11-27 20:15:23,307:INFO:SubProcess create_model() end ==================================
2024-11-27 20:15:23,307:INFO:Creating metrics dataframe
2024-11-27 20:15:23,309:INFO:Initializing Dummy Classifier
2024-11-27 20:15:23,309:INFO:Total runtime is 0.13573728799819945 minutes
2024-11-27 20:15:23,309:INFO:SubProcess create_model() called ==================================
2024-11-27 20:15:23,309:INFO:Initializing create_model()
2024-11-27 20:15:23,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019244ABFE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:23,309:INFO:Checking exceptions
2024-11-27 20:15:23,309:INFO:Importing libraries
2024-11-27 20:15:23,309:INFO:Copying training dataset
2024-11-27 20:15:23,309:INFO:Defining folds
2024-11-27 20:15:23,309:INFO:Declaring metric variables
2024-11-27 20:15:23,309:INFO:Importing untrained model
2024-11-27 20:15:23,309:INFO:Dummy Classifier Imported successfully
2024-11-27 20:15:23,309:INFO:Starting cross validation
2024-11-27 20:15:23,309:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:15:23,425:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:15:23,425:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:15:23,425:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:15:23,425:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:15:23,425:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:15:23,425:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:15:23,425:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:15:23,425:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:15:23,425:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:15:23,441:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:15:23,457:INFO:Calculating mean and std
2024-11-27 20:15:23,457:INFO:Creating metrics dataframe
2024-11-27 20:15:23,460:INFO:Uploading results into container
2024-11-27 20:15:23,460:INFO:Uploading model into container now
2024-11-27 20:15:23,461:INFO:_master_model_container: 14
2024-11-27 20:15:23,461:INFO:_display_container: 2
2024-11-27 20:15:23,461:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-11-27 20:15:23,461:INFO:create_model() successfully completed......................................
2024-11-27 20:15:23,509:INFO:SubProcess create_model() end ==================================
2024-11-27 20:15:23,509:INFO:Creating metrics dataframe
2024-11-27 20:15:23,509:INFO:Initializing create_model()
2024-11-27 20:15:23,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:23,509:INFO:Checking exceptions
2024-11-27 20:15:23,509:INFO:Importing libraries
2024-11-27 20:15:23,509:INFO:Copying training dataset
2024-11-27 20:15:23,509:INFO:Defining folds
2024-11-27 20:15:23,509:INFO:Declaring metric variables
2024-11-27 20:15:23,509:INFO:Importing untrained model
2024-11-27 20:15:23,509:INFO:Declaring custom model
2024-11-27 20:15:23,509:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-27 20:15:23,509:INFO:Cross validation set to False
2024-11-27 20:15:23,509:INFO:Fitting Model
2024-11-27 20:15:23,541:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-11-27 20:15:23,557:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.
2024-11-27 20:15:23,557:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-11-27 20:15:23,557:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-11-27 20:15:23,557:INFO:[LightGBM] [Info] Total Bins 191
2024-11-27 20:15:23,557:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-11-27 20:15:23,558:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-11-27 20:15:23,558:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:23,574:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-27 20:15:23,574:INFO:create_model() successfully completed......................................
2024-11-27 20:15:23,665:INFO:_master_model_container: 14
2024-11-27 20:15:23,666:INFO:_display_container: 2
2024-11-27 20:15:23,666:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-27 20:15:23,666:INFO:compare_models() successfully completed......................................
2024-11-27 20:15:23,670:INFO:Initializing tune_model()
2024-11-27 20:15:23,670:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>)
2024-11-27 20:15:23,670:INFO:Checking exceptions
2024-11-27 20:15:23,673:INFO:Copying training dataset
2024-11-27 20:15:23,674:INFO:Checking base model
2024-11-27 20:15:23,675:INFO:Base model : Light Gradient Boosting Machine
2024-11-27 20:15:23,675:INFO:Declaring metric variables
2024-11-27 20:15:23,676:INFO:Defining Hyperparameters
2024-11-27 20:15:23,739:INFO:Tuning with n_jobs=-1
2024-11-27 20:15:23,739:INFO:Initializing RandomizedSearchCV
2024-11-27 20:15:34,595:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 60, 'actual_estimator__n_estimators': 80, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__feature_fraction': 0.7, 'actual_estimator__bagging_freq': 7, 'actual_estimator__bagging_fraction': 1.0}
2024-11-27 20:15:34,600:INFO:Hyperparameter search completed
2024-11-27 20:15:34,600:INFO:SubProcess create_model() called ==================================
2024-11-27 20:15:34,601:INFO:Initializing create_model()
2024-11-27 20:15:34,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019245148FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.4, 'reg_alpha': 0.0005, 'num_leaves': 60, 'n_estimators': 80, 'min_split_gain': 0.2, 'min_child_samples': 11, 'learning_rate': 0.01, 'feature_fraction': 0.7, 'bagging_freq': 7, 'bagging_fraction': 1.0})
2024-11-27 20:15:34,601:INFO:Checking exceptions
2024-11-27 20:15:34,601:INFO:Importing libraries
2024-11-27 20:15:34,601:INFO:Copying training dataset
2024-11-27 20:15:34,606:INFO:Defining folds
2024-11-27 20:15:34,606:INFO:Declaring metric variables
2024-11-27 20:15:34,606:INFO:Importing untrained model
2024-11-27 20:15:34,606:INFO:Declaring custom model
2024-11-27 20:15:34,606:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-27 20:15:34,607:INFO:Starting cross validation
2024-11-27 20:15:34,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:15:35,710:INFO:Calculating mean and std
2024-11-27 20:15:35,711:INFO:Creating metrics dataframe
2024-11-27 20:15:35,713:INFO:Finalizing model
2024-11-27 20:15:35,760:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2024-11-27 20:15:35,760:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-11-27 20:15:35,760:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-11-27 20:15:35,760:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2024-11-27 20:15:35,761:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-11-27 20:15:35,761:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-11-27 20:15:35,761:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-11-27 20:15:35,761:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.
2024-11-27 20:15:35,761:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-11-27 20:15:35,761:INFO:[LightGBM] [Info] Total Bins 191
2024-11-27 20:15:35,761:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-11-27 20:15:35,761:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-11-27 20:15:35,762:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-11-27 20:15:35,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:35,808:INFO:Uploading results into container
2024-11-27 20:15:35,816:INFO:Uploading model into container now
2024-11-27 20:15:35,816:INFO:_master_model_container: 15
2024-11-27 20:15:35,816:INFO:_display_container: 3
2024-11-27 20:15:35,817:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=80, n_jobs=-1, num_leaves=60, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.4,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-11-27 20:15:35,817:INFO:create_model() successfully completed......................................
2024-11-27 20:15:35,875:INFO:SubProcess create_model() end ==================================
2024-11-27 20:15:35,875:INFO:choose_better activated
2024-11-27 20:15:35,875:INFO:SubProcess create_model() called ==================================
2024-11-27 20:15:35,875:INFO:Initializing create_model()
2024-11-27 20:15:35,875:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:35,875:INFO:Checking exceptions
2024-11-27 20:15:35,875:INFO:Importing libraries
2024-11-27 20:15:35,875:INFO:Copying training dataset
2024-11-27 20:15:35,875:INFO:Defining folds
2024-11-27 20:15:35,875:INFO:Declaring metric variables
2024-11-27 20:15:35,875:INFO:Importing untrained model
2024-11-27 20:15:35,875:INFO:Declaring custom model
2024-11-27 20:15:35,875:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-27 20:15:35,875:INFO:Starting cross validation
2024-11-27 20:15:35,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:15:36,988:INFO:Calculating mean and std
2024-11-27 20:15:36,988:INFO:Creating metrics dataframe
2024-11-27 20:15:36,991:INFO:Finalizing model
2024-11-27 20:15:37,026:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-11-27 20:15:37,026:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.
2024-11-27 20:15:37,026:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-11-27 20:15:37,026:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-11-27 20:15:37,026:INFO:[LightGBM] [Info] Total Bins 191
2024-11-27 20:15:37,026:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-11-27 20:15:37,026:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-11-27 20:15:37,026:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-11-27 20:15:37,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,092:INFO:Uploading results into container
2024-11-27 20:15:37,092:INFO:Uploading model into container now
2024-11-27 20:15:37,092:INFO:_master_model_container: 16
2024-11-27 20:15:37,092:INFO:_display_container: 4
2024-11-27 20:15:37,107:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-27 20:15:37,107:INFO:create_model() successfully completed......................................
2024-11-27 20:15:37,159:INFO:SubProcess create_model() end ==================================
2024-11-27 20:15:37,159:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8169
2024-11-27 20:15:37,159:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=80, n_jobs=-1, num_leaves=60, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.4,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8153
2024-11-27 20:15:37,159:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-11-27 20:15:37,159:INFO:choose_better completed
2024-11-27 20:15:37,175:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-11-27 20:15:37,188:INFO:_master_model_container: 16
2024-11-27 20:15:37,188:INFO:_display_container: 3
2024-11-27 20:15:37,189:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-27 20:15:37,189:INFO:tune_model() successfully completed......................................
2024-11-27 20:15:37,243:INFO:Initializing finalize_model()
2024-11-27 20:15:37,244:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-11-27 20:15:37,244:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-27 20:15:37,247:INFO:Initializing create_model()
2024-11-27 20:15:37,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:15:37,247:INFO:Checking exceptions
2024-11-27 20:15:37,248:INFO:Importing libraries
2024-11-27 20:15:37,248:INFO:Copying training dataset
2024-11-27 20:15:37,248:INFO:Defining folds
2024-11-27 20:15:37,248:INFO:Declaring metric variables
2024-11-27 20:15:37,249:INFO:Importing untrained model
2024-11-27 20:15:37,249:INFO:Declaring custom model
2024-11-27 20:15:37,250:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-27 20:15:37,251:INFO:Cross validation set to False
2024-11-27 20:15:37,251:INFO:Fitting Model
2024-11-27 20:15:37,281:INFO:[LightGBM] [Info] Number of positive: 342, number of negative: 549
2024-11-27 20:15:37,291:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000222 seconds.
2024-11-27 20:15:37,291:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-11-27 20:15:37,291:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-11-27 20:15:37,291:INFO:[LightGBM] [Info] Total Bins 224
2024-11-27 20:15:37,291:INFO:[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 9
2024-11-27 20:15:37,291:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288
2024-11-27 20:15:37,291:INFO:[LightGBM] [Info] Start training from score -0.473288
2024-11-27 20:15:37,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:15:37,343:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=['Sex...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-11-27 20:15:37,343:INFO:create_model() successfully completed......................................
2024-11-27 20:15:37,399:INFO:_master_model_container: 16
2024-11-27 20:15:37,399:INFO:_display_container: 3
2024-11-27 20:15:37,418:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=['Sex...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-11-27 20:15:37,419:INFO:finalize_model() successfully completed......................................
2024-11-27 20:15:37,483:INFO:Initializing predict_model()
2024-11-27 20:15:37,483:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019244ABF6A0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=['Sex...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000192450139D0>)
2024-11-27 20:15:37,483:INFO:Checking exceptions
2024-11-27 20:15:37,483:INFO:Preloading libraries
2024-11-27 20:16:05,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:16:05,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:16:05,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:16:05,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-27 20:16:10,583:INFO:PyCaret ClassificationExperiment
2024-11-27 20:16:10,583:INFO:Logging name: clf-default-name
2024-11-27 20:16:10,583:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-27 20:16:10,583:INFO:version 3.3.2
2024-11-27 20:16:10,583:INFO:Initializing setup()
2024-11-27 20:16:10,583:INFO:self.USI: 7a8a
2024-11-27 20:16:10,584:INFO:self._variable_keys: {'target_param', 'X', 'fold_shuffle_param', 'exp_name_log', 'log_plots_param', 'X_test', '_ml_usecase', 'fix_imbalance', 'X_train', 'y_train', 'seed', 'n_jobs_param', 'y_test', 'idx', 'gpu_param', 'logging_param', 'USI', 'y', 'exp_id', 'pipeline', 'data', 'is_multiclass', 'memory', '_available_plots', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'fold_generator'}
2024-11-27 20:16:10,584:INFO:Checking environment
2024-11-27 20:16:10,584:INFO:python_version: 3.9.1
2024-11-27 20:16:10,584:INFO:python_build: ('tags/v3.9.1:1e5d33e', 'Dec  7 2020 17:08:21')
2024-11-27 20:16:10,584:INFO:machine: AMD64
2024-11-27 20:16:10,584:INFO:platform: Windows-10-10.0.18362-SP0
2024-11-27 20:16:10,586:INFO:Memory: svmem(total=16973832192, available=10349309952, percent=39.0, used=6624522240, free=10349309952)
2024-11-27 20:16:10,586:INFO:Physical Core: 6
2024-11-27 20:16:10,586:INFO:Logical Core: 12
2024-11-27 20:16:10,586:INFO:Checking libraries
2024-11-27 20:16:10,586:INFO:System:
2024-11-27 20:16:10,586:INFO:    python: 3.9.1 (tags/v3.9.1:1e5d33e, Dec  7 2020, 17:08:21) [MSC v.1927 64 bit (AMD64)]
2024-11-27 20:16:10,586:INFO:executable: c:\users\user\appdata\local\programs\python\python39\python.exe
2024-11-27 20:16:10,586:INFO:   machine: Windows-10-10.0.18362-SP0
2024-11-27 20:16:10,586:INFO:PyCaret required dependencies:
2024-11-27 20:16:10,601:INFO:                 pip: 24.3.1
2024-11-27 20:16:10,601:INFO:          setuptools: 75.6.0
2024-11-27 20:16:10,601:INFO:             pycaret: 3.3.2
2024-11-27 20:16:10,601:INFO:             IPython: 8.18.1
2024-11-27 20:16:10,601:INFO:          ipywidgets: 8.1.5
2024-11-27 20:16:10,601:INFO:                tqdm: 4.67.1
2024-11-27 20:16:10,602:INFO:               numpy: 1.21.6
2024-11-27 20:16:10,602:INFO:              pandas: 1.3.5
2024-11-27 20:16:10,602:INFO:              jinja2: 3.1.4
2024-11-27 20:16:10,602:INFO:               scipy: 1.7.3
2024-11-27 20:16:10,602:INFO:              joblib: 1.3.2
2024-11-27 20:16:10,602:INFO:             sklearn: 1.4.2
2024-11-27 20:16:10,602:INFO:                pyod: 2.0.2
2024-11-27 20:16:10,602:INFO:            imblearn: 0.12.4
2024-11-27 20:16:10,602:INFO:   category_encoders: 2.6.4
2024-11-27 20:16:10,602:INFO:            lightgbm: 4.5.0
2024-11-27 20:16:10,602:INFO:               numba: 0.58.0
2024-11-27 20:16:10,602:INFO:            requests: 2.32.3
2024-11-27 20:16:10,602:INFO:          matplotlib: 3.7.5
2024-11-27 20:16:10,602:INFO:          scikitplot: 0.3.7
2024-11-27 20:16:10,602:INFO:         yellowbrick: 1.5
2024-11-27 20:16:10,602:INFO:              plotly: 5.24.1
2024-11-27 20:16:10,602:INFO:    plotly-resampler: Not installed
2024-11-27 20:16:10,602:INFO:             kaleido: 0.2.1
2024-11-27 20:16:10,602:INFO:           schemdraw: 0.15
2024-11-27 20:16:10,602:INFO:         statsmodels: 0.14.1
2024-11-27 20:16:10,602:INFO:              sktime: 0.26.0
2024-11-27 20:16:10,602:INFO:               tbats: 1.1.3
2024-11-27 20:16:10,602:INFO:            pmdarima: 2.0.4
2024-11-27 20:16:10,602:INFO:              psutil: 6.1.0
2024-11-27 20:16:10,602:INFO:          markupsafe: 3.0.2
2024-11-27 20:16:10,602:INFO:             pickle5: Not installed
2024-11-27 20:16:10,602:INFO:         cloudpickle: 3.1.0
2024-11-27 20:16:10,602:INFO:         deprecation: 2.1.0
2024-11-27 20:16:10,602:INFO:              xxhash: 3.5.0
2024-11-27 20:16:10,602:INFO:           wurlitzer: Not installed
2024-11-27 20:16:10,602:INFO:PyCaret optional dependencies:
2024-11-27 20:16:10,609:INFO:                shap: Not installed
2024-11-27 20:16:10,609:INFO:           interpret: Not installed
2024-11-27 20:16:10,609:INFO:                umap: Not installed
2024-11-27 20:16:10,609:INFO:     ydata_profiling: Not installed
2024-11-27 20:16:10,609:INFO:  explainerdashboard: Not installed
2024-11-27 20:16:10,609:INFO:             autoviz: Not installed
2024-11-27 20:16:10,609:INFO:           fairlearn: Not installed
2024-11-27 20:16:10,609:INFO:          deepchecks: Not installed
2024-11-27 20:16:10,609:INFO:             xgboost: Not installed
2024-11-27 20:16:10,609:INFO:            catboost: Not installed
2024-11-27 20:16:10,609:INFO:              kmodes: Not installed
2024-11-27 20:16:10,609:INFO:             mlxtend: Not installed
2024-11-27 20:16:10,609:INFO:       statsforecast: Not installed
2024-11-27 20:16:10,609:INFO:        tune_sklearn: Not installed
2024-11-27 20:16:10,609:INFO:                 ray: Not installed
2024-11-27 20:16:10,609:INFO:            hyperopt: Not installed
2024-11-27 20:16:10,610:INFO:              optuna: 4.1.0
2024-11-27 20:16:10,610:INFO:               skopt: Not installed
2024-11-27 20:16:10,610:INFO:              mlflow: Not installed
2024-11-27 20:16:10,610:INFO:              gradio: Not installed
2024-11-27 20:16:10,610:INFO:             fastapi: Not installed
2024-11-27 20:16:10,610:INFO:             uvicorn: Not installed
2024-11-27 20:16:10,610:INFO:              m2cgen: Not installed
2024-11-27 20:16:10,610:INFO:           evidently: Not installed
2024-11-27 20:16:10,610:INFO:               fugue: Not installed
2024-11-27 20:16:10,610:INFO:           streamlit: 1.38.0
2024-11-27 20:16:10,610:INFO:             prophet: Not installed
2024-11-27 20:16:10,610:INFO:None
2024-11-27 20:16:10,610:INFO:Set up data.
2024-11-27 20:16:10,616:INFO:Set up folding strategy.
2024-11-27 20:16:10,616:INFO:Set up train/test split.
2024-11-27 20:16:10,620:INFO:Set up index.
2024-11-27 20:16:10,620:INFO:Assigning column types.
2024-11-27 20:16:10,625:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-27 20:16:10,660:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-27 20:16:10,660:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-27 20:16:10,692:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:16:10,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:16:10,744:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-27 20:16:10,745:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-27 20:16:10,774:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:16:10,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:16:10,775:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-27 20:16:10,809:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-27 20:16:10,829:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:16:10,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:16:10,863:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-27 20:16:10,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:16:10,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:16:10,883:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-27 20:16:10,936:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:16:10,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:16:10,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:16:10,989:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:16:10,991:INFO:Preparing preprocessing pipeline...
2024-11-27 20:16:10,992:INFO:Set up simple imputation.
2024-11-27 20:16:10,993:INFO:Set up encoding of ordinal features.
2024-11-27 20:16:10,994:INFO:Set up encoding of categorical features.
2024-11-27 20:16:11,045:INFO:Finished creating preprocessing pipeline.
2024-11-27 20:16:11,064:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-11-27 20:16:11,064:INFO:Creating final display dataframe.
2024-11-27 20:16:11,209:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              7a8a
2024-11-27 20:16:11,299:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:16:11,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:16:11,342:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:16:11,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-27 20:16:11,342:INFO:setup() successfully completed in 0.76s...............
2024-11-27 20:16:11,360:INFO:Initializing compare_models()
2024-11-27 20:16:11,360:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-11-27 20:16:11,360:INFO:Checking exceptions
2024-11-27 20:16:11,362:INFO:Preparing display monitor
2024-11-27 20:16:11,365:INFO:Initializing Logistic Regression
2024-11-27 20:16:11,365:INFO:Total runtime is 0.0 minutes
2024-11-27 20:16:11,365:INFO:SubProcess create_model() called ==================================
2024-11-27 20:16:11,365:INFO:Initializing create_model()
2024-11-27 20:16:11,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EC9ED16B20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:11,365:INFO:Checking exceptions
2024-11-27 20:16:11,365:INFO:Importing libraries
2024-11-27 20:16:11,365:INFO:Copying training dataset
2024-11-27 20:16:11,368:INFO:Defining folds
2024-11-27 20:16:11,368:INFO:Declaring metric variables
2024-11-27 20:16:11,368:INFO:Importing untrained model
2024-11-27 20:16:11,369:INFO:Logistic Regression Imported successfully
2024-11-27 20:16:11,369:INFO:Starting cross validation
2024-11-27 20:16:11,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:16:13,658:INFO:Calculating mean and std
2024-11-27 20:16:13,658:INFO:Creating metrics dataframe
2024-11-27 20:16:13,665:INFO:Uploading results into container
2024-11-27 20:16:13,666:INFO:Uploading model into container now
2024-11-27 20:16:13,666:INFO:_master_model_container: 1
2024-11-27 20:16:13,666:INFO:_display_container: 2
2024-11-27 20:16:13,667:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-27 20:16:13,667:INFO:create_model() successfully completed......................................
2024-11-27 20:16:13,741:INFO:SubProcess create_model() end ==================================
2024-11-27 20:16:13,741:INFO:Creating metrics dataframe
2024-11-27 20:16:13,758:INFO:Initializing K Neighbors Classifier
2024-11-27 20:16:13,758:INFO:Total runtime is 0.0398895263671875 minutes
2024-11-27 20:16:13,758:INFO:SubProcess create_model() called ==================================
2024-11-27 20:16:13,758:INFO:Initializing create_model()
2024-11-27 20:16:13,758:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EC9ED16B20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:13,758:INFO:Checking exceptions
2024-11-27 20:16:13,758:INFO:Importing libraries
2024-11-27 20:16:13,758:INFO:Copying training dataset
2024-11-27 20:16:13,758:INFO:Defining folds
2024-11-27 20:16:13,758:INFO:Declaring metric variables
2024-11-27 20:16:13,758:INFO:Importing untrained model
2024-11-27 20:16:13,758:INFO:K Neighbors Classifier Imported successfully
2024-11-27 20:16:13,758:INFO:Starting cross validation
2024-11-27 20:16:13,758:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:16:15,042:INFO:Calculating mean and std
2024-11-27 20:16:15,042:INFO:Creating metrics dataframe
2024-11-27 20:16:15,045:INFO:Uploading results into container
2024-11-27 20:16:15,046:INFO:Uploading model into container now
2024-11-27 20:16:15,046:INFO:_master_model_container: 2
2024-11-27 20:16:15,046:INFO:_display_container: 2
2024-11-27 20:16:15,046:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-27 20:16:15,046:INFO:create_model() successfully completed......................................
2024-11-27 20:16:15,092:INFO:SubProcess create_model() end ==================================
2024-11-27 20:16:15,092:INFO:Creating metrics dataframe
2024-11-27 20:16:15,092:INFO:Initializing Naive Bayes
2024-11-27 20:16:15,092:INFO:Total runtime is 0.06213118235270182 minutes
2024-11-27 20:16:15,092:INFO:SubProcess create_model() called ==================================
2024-11-27 20:16:15,092:INFO:Initializing create_model()
2024-11-27 20:16:15,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EC9ED16B20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:15,092:INFO:Checking exceptions
2024-11-27 20:16:15,092:INFO:Importing libraries
2024-11-27 20:16:15,092:INFO:Copying training dataset
2024-11-27 20:16:15,108:INFO:Defining folds
2024-11-27 20:16:15,108:INFO:Declaring metric variables
2024-11-27 20:16:15,108:INFO:Importing untrained model
2024-11-27 20:16:15,108:INFO:Naive Bayes Imported successfully
2024-11-27 20:16:15,108:INFO:Starting cross validation
2024-11-27 20:16:15,108:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:16:15,240:INFO:Calculating mean and std
2024-11-27 20:16:15,241:INFO:Creating metrics dataframe
2024-11-27 20:16:15,244:INFO:Uploading results into container
2024-11-27 20:16:15,244:INFO:Uploading model into container now
2024-11-27 20:16:15,245:INFO:_master_model_container: 3
2024-11-27 20:16:15,245:INFO:_display_container: 2
2024-11-27 20:16:15,245:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-27 20:16:15,245:INFO:create_model() successfully completed......................................
2024-11-27 20:16:15,292:INFO:SubProcess create_model() end ==================================
2024-11-27 20:16:15,292:INFO:Creating metrics dataframe
2024-11-27 20:16:15,292:INFO:Initializing Decision Tree Classifier
2024-11-27 20:16:15,292:INFO:Total runtime is 0.06545931498209635 minutes
2024-11-27 20:16:15,292:INFO:SubProcess create_model() called ==================================
2024-11-27 20:16:15,292:INFO:Initializing create_model()
2024-11-27 20:16:15,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EC9ED16B20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:15,292:INFO:Checking exceptions
2024-11-27 20:16:15,292:INFO:Importing libraries
2024-11-27 20:16:15,292:INFO:Copying training dataset
2024-11-27 20:16:15,292:INFO:Defining folds
2024-11-27 20:16:15,292:INFO:Declaring metric variables
2024-11-27 20:16:15,292:INFO:Importing untrained model
2024-11-27 20:16:15,292:INFO:Decision Tree Classifier Imported successfully
2024-11-27 20:16:15,292:INFO:Starting cross validation
2024-11-27 20:16:15,292:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:16:15,441:INFO:Calculating mean and std
2024-11-27 20:16:15,441:INFO:Creating metrics dataframe
2024-11-27 20:16:15,444:INFO:Uploading results into container
2024-11-27 20:16:15,444:INFO:Uploading model into container now
2024-11-27 20:16:15,445:INFO:_master_model_container: 4
2024-11-27 20:16:15,445:INFO:_display_container: 2
2024-11-27 20:16:15,445:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-27 20:16:15,445:INFO:create_model() successfully completed......................................
2024-11-27 20:16:15,493:INFO:SubProcess create_model() end ==================================
2024-11-27 20:16:15,493:INFO:Creating metrics dataframe
2024-11-27 20:16:15,493:INFO:Initializing SVM - Linear Kernel
2024-11-27 20:16:15,493:INFO:Total runtime is 0.06879866123199463 minutes
2024-11-27 20:16:15,493:INFO:SubProcess create_model() called ==================================
2024-11-27 20:16:15,493:INFO:Initializing create_model()
2024-11-27 20:16:15,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EC9ED16B20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:15,493:INFO:Checking exceptions
2024-11-27 20:16:15,493:INFO:Importing libraries
2024-11-27 20:16:15,493:INFO:Copying training dataset
2024-11-27 20:16:15,493:INFO:Defining folds
2024-11-27 20:16:15,493:INFO:Declaring metric variables
2024-11-27 20:16:15,493:INFO:Importing untrained model
2024-11-27 20:16:15,493:INFO:SVM - Linear Kernel Imported successfully
2024-11-27 20:16:15,493:INFO:Starting cross validation
2024-11-27 20:16:15,493:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:16:15,609:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:16:15,625:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:16:15,641:INFO:Calculating mean and std
2024-11-27 20:16:15,641:INFO:Creating metrics dataframe
2024-11-27 20:16:15,645:INFO:Uploading results into container
2024-11-27 20:16:15,645:INFO:Uploading model into container now
2024-11-27 20:16:15,645:INFO:_master_model_container: 5
2024-11-27 20:16:15,646:INFO:_display_container: 2
2024-11-27 20:16:15,646:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-27 20:16:15,646:INFO:create_model() successfully completed......................................
2024-11-27 20:16:15,692:INFO:SubProcess create_model() end ==================================
2024-11-27 20:16:15,692:INFO:Creating metrics dataframe
2024-11-27 20:16:15,692:INFO:Initializing Ridge Classifier
2024-11-27 20:16:15,692:INFO:Total runtime is 0.07212000687917074 minutes
2024-11-27 20:16:15,692:INFO:SubProcess create_model() called ==================================
2024-11-27 20:16:15,692:INFO:Initializing create_model()
2024-11-27 20:16:15,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EC9ED16B20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:15,692:INFO:Checking exceptions
2024-11-27 20:16:15,692:INFO:Importing libraries
2024-11-27 20:16:15,692:INFO:Copying training dataset
2024-11-27 20:16:15,692:INFO:Defining folds
2024-11-27 20:16:15,692:INFO:Declaring metric variables
2024-11-27 20:16:15,692:INFO:Importing untrained model
2024-11-27 20:16:15,692:INFO:Ridge Classifier Imported successfully
2024-11-27 20:16:15,692:INFO:Starting cross validation
2024-11-27 20:16:15,692:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:16:15,840:INFO:Calculating mean and std
2024-11-27 20:16:15,841:INFO:Creating metrics dataframe
2024-11-27 20:16:15,844:INFO:Uploading results into container
2024-11-27 20:16:15,844:INFO:Uploading model into container now
2024-11-27 20:16:15,845:INFO:_master_model_container: 6
2024-11-27 20:16:15,845:INFO:_display_container: 2
2024-11-27 20:16:15,845:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-27 20:16:15,845:INFO:create_model() successfully completed......................................
2024-11-27 20:16:15,892:INFO:SubProcess create_model() end ==================================
2024-11-27 20:16:15,892:INFO:Creating metrics dataframe
2024-11-27 20:16:15,892:INFO:Initializing Random Forest Classifier
2024-11-27 20:16:15,892:INFO:Total runtime is 0.0754637320836385 minutes
2024-11-27 20:16:15,892:INFO:SubProcess create_model() called ==================================
2024-11-27 20:16:15,892:INFO:Initializing create_model()
2024-11-27 20:16:15,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EC9ED16B20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:15,892:INFO:Checking exceptions
2024-11-27 20:16:15,892:INFO:Importing libraries
2024-11-27 20:16:15,892:INFO:Copying training dataset
2024-11-27 20:16:15,892:INFO:Defining folds
2024-11-27 20:16:15,892:INFO:Declaring metric variables
2024-11-27 20:16:15,892:INFO:Importing untrained model
2024-11-27 20:16:15,892:INFO:Random Forest Classifier Imported successfully
2024-11-27 20:16:15,892:INFO:Starting cross validation
2024-11-27 20:16:15,892:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:16:16,290:INFO:Calculating mean and std
2024-11-27 20:16:16,291:INFO:Creating metrics dataframe
2024-11-27 20:16:16,294:INFO:Uploading results into container
2024-11-27 20:16:16,295:INFO:Uploading model into container now
2024-11-27 20:16:16,295:INFO:_master_model_container: 7
2024-11-27 20:16:16,295:INFO:_display_container: 2
2024-11-27 20:16:16,295:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-27 20:16:16,295:INFO:create_model() successfully completed......................................
2024-11-27 20:16:16,343:INFO:SubProcess create_model() end ==================================
2024-11-27 20:16:16,343:INFO:Creating metrics dataframe
2024-11-27 20:16:16,343:INFO:Initializing Quadratic Discriminant Analysis
2024-11-27 20:16:16,343:INFO:Total runtime is 0.08296958605448404 minutes
2024-11-27 20:16:16,343:INFO:SubProcess create_model() called ==================================
2024-11-27 20:16:16,343:INFO:Initializing create_model()
2024-11-27 20:16:16,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EC9ED16B20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:16,343:INFO:Checking exceptions
2024-11-27 20:16:16,343:INFO:Importing libraries
2024-11-27 20:16:16,343:INFO:Copying training dataset
2024-11-27 20:16:16,343:INFO:Defining folds
2024-11-27 20:16:16,343:INFO:Declaring metric variables
2024-11-27 20:16:16,343:INFO:Importing untrained model
2024-11-27 20:16:16,343:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-27 20:16:16,343:INFO:Starting cross validation
2024-11-27 20:16:16,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:16:16,409:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:16:16,409:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:16:16,409:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:16:16,409:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:16:16,409:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:16:16,426:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:16:16,426:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:16:16,426:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:16:16,426:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:16:16,426:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:16:16,491:INFO:Calculating mean and std
2024-11-27 20:16:16,491:INFO:Creating metrics dataframe
2024-11-27 20:16:16,494:INFO:Uploading results into container
2024-11-27 20:16:16,495:INFO:Uploading model into container now
2024-11-27 20:16:16,495:INFO:_master_model_container: 8
2024-11-27 20:16:16,495:INFO:_display_container: 2
2024-11-27 20:16:16,495:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-27 20:16:16,495:INFO:create_model() successfully completed......................................
2024-11-27 20:16:16,542:INFO:SubProcess create_model() end ==================================
2024-11-27 20:16:16,542:INFO:Creating metrics dataframe
2024-11-27 20:16:16,542:INFO:Initializing Ada Boost Classifier
2024-11-27 20:16:16,542:INFO:Total runtime is 0.08629531462987262 minutes
2024-11-27 20:16:16,542:INFO:SubProcess create_model() called ==================================
2024-11-27 20:16:16,542:INFO:Initializing create_model()
2024-11-27 20:16:16,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EC9ED16B20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:16,542:INFO:Checking exceptions
2024-11-27 20:16:16,542:INFO:Importing libraries
2024-11-27 20:16:16,542:INFO:Copying training dataset
2024-11-27 20:16:16,542:INFO:Defining folds
2024-11-27 20:16:16,542:INFO:Declaring metric variables
2024-11-27 20:16:16,542:INFO:Importing untrained model
2024-11-27 20:16:16,542:INFO:Ada Boost Classifier Imported successfully
2024-11-27 20:16:16,542:INFO:Starting cross validation
2024-11-27 20:16:16,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:16:16,608:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:16:16,608:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:16:16,608:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:16:16,608:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:16:16,625:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:16:16,625:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:16:16,625:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:16:16,625:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:16:16,625:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:16:16,625:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:16:16,808:INFO:Calculating mean and std
2024-11-27 20:16:16,809:INFO:Creating metrics dataframe
2024-11-27 20:16:16,811:INFO:Uploading results into container
2024-11-27 20:16:16,811:INFO:Uploading model into container now
2024-11-27 20:16:16,812:INFO:_master_model_container: 9
2024-11-27 20:16:16,812:INFO:_display_container: 2
2024-11-27 20:16:16,812:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-27 20:16:16,812:INFO:create_model() successfully completed......................................
2024-11-27 20:16:16,860:INFO:SubProcess create_model() end ==================================
2024-11-27 20:16:16,860:INFO:Creating metrics dataframe
2024-11-27 20:16:16,860:INFO:Initializing Gradient Boosting Classifier
2024-11-27 20:16:16,860:INFO:Total runtime is 0.09158293008804319 minutes
2024-11-27 20:16:16,860:INFO:SubProcess create_model() called ==================================
2024-11-27 20:16:16,860:INFO:Initializing create_model()
2024-11-27 20:16:16,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EC9ED16B20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:16,860:INFO:Checking exceptions
2024-11-27 20:16:16,860:INFO:Importing libraries
2024-11-27 20:16:16,860:INFO:Copying training dataset
2024-11-27 20:16:16,860:INFO:Defining folds
2024-11-27 20:16:16,860:INFO:Declaring metric variables
2024-11-27 20:16:16,860:INFO:Importing untrained model
2024-11-27 20:16:16,860:INFO:Gradient Boosting Classifier Imported successfully
2024-11-27 20:16:16,860:INFO:Starting cross validation
2024-11-27 20:16:16,860:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:16:17,174:INFO:Calculating mean and std
2024-11-27 20:16:17,175:INFO:Creating metrics dataframe
2024-11-27 20:16:17,178:INFO:Uploading results into container
2024-11-27 20:16:17,178:INFO:Uploading model into container now
2024-11-27 20:16:17,179:INFO:_master_model_container: 10
2024-11-27 20:16:17,179:INFO:_display_container: 2
2024-11-27 20:16:17,179:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-27 20:16:17,179:INFO:create_model() successfully completed......................................
2024-11-27 20:16:17,226:INFO:SubProcess create_model() end ==================================
2024-11-27 20:16:17,226:INFO:Creating metrics dataframe
2024-11-27 20:16:17,226:INFO:Initializing Linear Discriminant Analysis
2024-11-27 20:16:17,226:INFO:Total runtime is 0.09769717852274575 minutes
2024-11-27 20:16:17,226:INFO:SubProcess create_model() called ==================================
2024-11-27 20:16:17,226:INFO:Initializing create_model()
2024-11-27 20:16:17,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EC9ED16B20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:17,226:INFO:Checking exceptions
2024-11-27 20:16:17,226:INFO:Importing libraries
2024-11-27 20:16:17,226:INFO:Copying training dataset
2024-11-27 20:16:17,226:INFO:Defining folds
2024-11-27 20:16:17,226:INFO:Declaring metric variables
2024-11-27 20:16:17,226:INFO:Importing untrained model
2024-11-27 20:16:17,226:INFO:Linear Discriminant Analysis Imported successfully
2024-11-27 20:16:17,226:INFO:Starting cross validation
2024-11-27 20:16:17,226:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:16:17,375:INFO:Calculating mean and std
2024-11-27 20:16:17,375:INFO:Creating metrics dataframe
2024-11-27 20:16:17,378:INFO:Uploading results into container
2024-11-27 20:16:17,379:INFO:Uploading model into container now
2024-11-27 20:16:17,379:INFO:_master_model_container: 11
2024-11-27 20:16:17,379:INFO:_display_container: 2
2024-11-27 20:16:17,379:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-27 20:16:17,379:INFO:create_model() successfully completed......................................
2024-11-27 20:16:17,426:INFO:SubProcess create_model() end ==================================
2024-11-27 20:16:17,426:INFO:Creating metrics dataframe
2024-11-27 20:16:17,426:INFO:Initializing Extra Trees Classifier
2024-11-27 20:16:17,426:INFO:Total runtime is 0.10102097193400063 minutes
2024-11-27 20:16:17,426:INFO:SubProcess create_model() called ==================================
2024-11-27 20:16:17,426:INFO:Initializing create_model()
2024-11-27 20:16:17,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EC9ED16B20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:17,426:INFO:Checking exceptions
2024-11-27 20:16:17,426:INFO:Importing libraries
2024-11-27 20:16:17,426:INFO:Copying training dataset
2024-11-27 20:16:17,426:INFO:Defining folds
2024-11-27 20:16:17,426:INFO:Declaring metric variables
2024-11-27 20:16:17,426:INFO:Importing untrained model
2024-11-27 20:16:17,426:INFO:Extra Trees Classifier Imported successfully
2024-11-27 20:16:17,426:INFO:Starting cross validation
2024-11-27 20:16:17,426:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:16:17,791:INFO:Calculating mean and std
2024-11-27 20:16:17,791:INFO:Creating metrics dataframe
2024-11-27 20:16:17,795:INFO:Uploading results into container
2024-11-27 20:16:17,795:INFO:Uploading model into container now
2024-11-27 20:16:17,795:INFO:_master_model_container: 12
2024-11-27 20:16:17,795:INFO:_display_container: 2
2024-11-27 20:16:17,796:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-27 20:16:17,796:INFO:create_model() successfully completed......................................
2024-11-27 20:16:17,851:INFO:SubProcess create_model() end ==================================
2024-11-27 20:16:17,851:INFO:Creating metrics dataframe
2024-11-27 20:16:17,855:INFO:Initializing Light Gradient Boosting Machine
2024-11-27 20:16:17,855:INFO:Total runtime is 0.10817942619323728 minutes
2024-11-27 20:16:17,855:INFO:SubProcess create_model() called ==================================
2024-11-27 20:16:17,856:INFO:Initializing create_model()
2024-11-27 20:16:17,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EC9ED16B20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:17,856:INFO:Checking exceptions
2024-11-27 20:16:17,856:INFO:Importing libraries
2024-11-27 20:16:17,856:INFO:Copying training dataset
2024-11-27 20:16:17,859:INFO:Defining folds
2024-11-27 20:16:17,859:INFO:Declaring metric variables
2024-11-27 20:16:17,859:INFO:Importing untrained model
2024-11-27 20:16:17,859:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-27 20:16:17,859:INFO:Starting cross validation
2024-11-27 20:16:17,859:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:16:19,717:INFO:Calculating mean and std
2024-11-27 20:16:19,718:INFO:Creating metrics dataframe
2024-11-27 20:16:19,722:INFO:Uploading results into container
2024-11-27 20:16:19,722:INFO:Uploading model into container now
2024-11-27 20:16:19,722:INFO:_master_model_container: 13
2024-11-27 20:16:19,722:INFO:_display_container: 2
2024-11-27 20:16:19,722:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-27 20:16:19,722:INFO:create_model() successfully completed......................................
2024-11-27 20:16:19,775:INFO:SubProcess create_model() end ==================================
2024-11-27 20:16:19,775:INFO:Creating metrics dataframe
2024-11-27 20:16:19,775:INFO:Initializing Dummy Classifier
2024-11-27 20:16:19,775:INFO:Total runtime is 0.1401801307996114 minutes
2024-11-27 20:16:19,775:INFO:SubProcess create_model() called ==================================
2024-11-27 20:16:19,775:INFO:Initializing create_model()
2024-11-27 20:16:19,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EC9ED16B20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:19,775:INFO:Checking exceptions
2024-11-27 20:16:19,775:INFO:Importing libraries
2024-11-27 20:16:19,775:INFO:Copying training dataset
2024-11-27 20:16:19,791:INFO:Defining folds
2024-11-27 20:16:19,791:INFO:Declaring metric variables
2024-11-27 20:16:19,791:INFO:Importing untrained model
2024-11-27 20:16:19,791:INFO:Dummy Classifier Imported successfully
2024-11-27 20:16:19,791:INFO:Starting cross validation
2024-11-27 20:16:19,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-27 20:16:19,892:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:16:19,892:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:16:19,892:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:16:19,908:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:16:19,908:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:16:19,908:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:16:19,908:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:16:19,908:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:16:19,908:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:16:19,908:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-27 20:16:19,924:INFO:Calculating mean and std
2024-11-27 20:16:19,925:INFO:Creating metrics dataframe
2024-11-27 20:16:19,927:INFO:Uploading results into container
2024-11-27 20:16:19,927:INFO:Uploading model into container now
2024-11-27 20:16:19,928:INFO:_master_model_container: 14
2024-11-27 20:16:19,928:INFO:_display_container: 2
2024-11-27 20:16:19,928:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-11-27 20:16:19,928:INFO:create_model() successfully completed......................................
2024-11-27 20:16:19,976:INFO:SubProcess create_model() end ==================================
2024-11-27 20:16:19,976:INFO:Creating metrics dataframe
2024-11-27 20:16:19,976:INFO:Initializing create_model()
2024-11-27 20:16:19,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:19,976:INFO:Checking exceptions
2024-11-27 20:16:19,976:INFO:Importing libraries
2024-11-27 20:16:19,976:INFO:Copying training dataset
2024-11-27 20:16:19,976:INFO:Defining folds
2024-11-27 20:16:19,976:INFO:Declaring metric variables
2024-11-27 20:16:19,976:INFO:Importing untrained model
2024-11-27 20:16:19,976:INFO:Declaring custom model
2024-11-27 20:16:19,976:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-27 20:16:19,976:INFO:Cross validation set to False
2024-11-27 20:16:19,976:INFO:Fitting Model
2024-11-27 20:16:20,025:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-11-27 20:16:20,025:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.
2024-11-27 20:16:20,025:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-11-27 20:16:20,025:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-11-27 20:16:20,025:INFO:[LightGBM] [Info] Total Bins 191
2024-11-27 20:16:20,025:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-11-27 20:16:20,025:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-11-27 20:16:20,025:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-27 20:16:20,058:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-27 20:16:20,058:INFO:create_model() successfully completed......................................
2024-11-27 20:16:20,117:INFO:Initializing create_model()
2024-11-27 20:16:20,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:20,118:INFO:Checking exceptions
2024-11-27 20:16:20,118:INFO:Importing libraries
2024-11-27 20:16:20,118:INFO:Copying training dataset
2024-11-27 20:16:20,121:INFO:Defining folds
2024-11-27 20:16:20,121:INFO:Declaring metric variables
2024-11-27 20:16:20,122:INFO:Importing untrained model
2024-11-27 20:16:20,122:INFO:Declaring custom model
2024-11-27 20:16:20,123:INFO:Gradient Boosting Classifier Imported successfully
2024-11-27 20:16:20,124:INFO:Cross validation set to False
2024-11-27 20:16:20,124:INFO:Fitting Model
2024-11-27 20:16:20,259:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-27 20:16:20,259:INFO:create_model() successfully completed......................................
2024-11-27 20:16:20,308:INFO:Initializing create_model()
2024-11-27 20:16:20,308:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:20,308:INFO:Checking exceptions
2024-11-27 20:16:20,308:INFO:Importing libraries
2024-11-27 20:16:20,308:INFO:Copying training dataset
2024-11-27 20:16:20,308:INFO:Defining folds
2024-11-27 20:16:20,308:INFO:Declaring metric variables
2024-11-27 20:16:20,308:INFO:Importing untrained model
2024-11-27 20:16:20,308:INFO:Declaring custom model
2024-11-27 20:16:20,308:INFO:Random Forest Classifier Imported successfully
2024-11-27 20:16:20,308:INFO:Cross validation set to False
2024-11-27 20:16:20,308:INFO:Fitting Model
2024-11-27 20:16:20,476:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-27 20:16:20,476:INFO:create_model() successfully completed......................................
2024-11-27 20:16:20,528:INFO:Initializing create_model()
2024-11-27 20:16:20,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:20,528:INFO:Checking exceptions
2024-11-27 20:16:20,529:INFO:Importing libraries
2024-11-27 20:16:20,529:INFO:Copying training dataset
2024-11-27 20:16:20,531:INFO:Defining folds
2024-11-27 20:16:20,531:INFO:Declaring metric variables
2024-11-27 20:16:20,531:INFO:Importing untrained model
2024-11-27 20:16:20,531:INFO:Declaring custom model
2024-11-27 20:16:20,532:INFO:Ada Boost Classifier Imported successfully
2024-11-27 20:16:20,533:INFO:Cross validation set to False
2024-11-27 20:16:20,533:INFO:Fitting Model
2024-11-27 20:16:20,567:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-27 20:16:20,625:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-27 20:16:20,625:INFO:create_model() successfully completed......................................
2024-11-27 20:16:20,675:INFO:Initializing create_model()
2024-11-27 20:16:20,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:20,675:INFO:Checking exceptions
2024-11-27 20:16:20,675:INFO:Importing libraries
2024-11-27 20:16:20,675:INFO:Copying training dataset
2024-11-27 20:16:20,675:INFO:Defining folds
2024-11-27 20:16:20,675:INFO:Declaring metric variables
2024-11-27 20:16:20,675:INFO:Importing untrained model
2024-11-27 20:16:20,675:INFO:Declaring custom model
2024-11-27 20:16:20,675:INFO:Logistic Regression Imported successfully
2024-11-27 20:16:20,675:INFO:Cross validation set to False
2024-11-27 20:16:20,675:INFO:Fitting Model
2024-11-27 20:16:20,725:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-27 20:16:20,725:INFO:create_model() successfully completed......................................
2024-11-27 20:16:20,789:INFO:Initializing create_model()
2024-11-27 20:16:20,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:20,789:INFO:Checking exceptions
2024-11-27 20:16:20,789:INFO:Importing libraries
2024-11-27 20:16:20,789:INFO:Copying training dataset
2024-11-27 20:16:20,792:INFO:Defining folds
2024-11-27 20:16:20,792:INFO:Declaring metric variables
2024-11-27 20:16:20,793:INFO:Importing untrained model
2024-11-27 20:16:20,793:INFO:Declaring custom model
2024-11-27 20:16:20,793:INFO:Extra Trees Classifier Imported successfully
2024-11-27 20:16:20,794:INFO:Cross validation set to False
2024-11-27 20:16:20,794:INFO:Fitting Model
2024-11-27 20:16:20,908:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-27 20:16:20,908:INFO:create_model() successfully completed......................................
2024-11-27 20:16:20,958:INFO:Initializing create_model()
2024-11-27 20:16:20,958:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:20,958:INFO:Checking exceptions
2024-11-27 20:16:20,958:INFO:Importing libraries
2024-11-27 20:16:20,958:INFO:Copying training dataset
2024-11-27 20:16:20,958:INFO:Defining folds
2024-11-27 20:16:20,958:INFO:Declaring metric variables
2024-11-27 20:16:20,958:INFO:Importing untrained model
2024-11-27 20:16:20,958:INFO:Declaring custom model
2024-11-27 20:16:20,958:INFO:Ridge Classifier Imported successfully
2024-11-27 20:16:20,958:INFO:Cross validation set to False
2024-11-27 20:16:20,958:INFO:Fitting Model
2024-11-27 20:16:20,992:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-27 20:16:20,992:INFO:create_model() successfully completed......................................
2024-11-27 20:16:21,058:INFO:Initializing create_model()
2024-11-27 20:16:21,059:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:21,059:INFO:Checking exceptions
2024-11-27 20:16:21,059:INFO:Importing libraries
2024-11-27 20:16:21,059:INFO:Copying training dataset
2024-11-27 20:16:21,062:INFO:Defining folds
2024-11-27 20:16:21,062:INFO:Declaring metric variables
2024-11-27 20:16:21,063:INFO:Importing untrained model
2024-11-27 20:16:21,063:INFO:Declaring custom model
2024-11-27 20:16:21,063:INFO:Linear Discriminant Analysis Imported successfully
2024-11-27 20:16:21,064:INFO:Cross validation set to False
2024-11-27 20:16:21,064:INFO:Fitting Model
2024-11-27 20:16:21,099:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-27 20:16:21,099:INFO:create_model() successfully completed......................................
2024-11-27 20:16:21,142:INFO:Initializing create_model()
2024-11-27 20:16:21,142:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:21,142:INFO:Checking exceptions
2024-11-27 20:16:21,142:INFO:Importing libraries
2024-11-27 20:16:21,142:INFO:Copying training dataset
2024-11-27 20:16:21,142:INFO:Defining folds
2024-11-27 20:16:21,142:INFO:Declaring metric variables
2024-11-27 20:16:21,142:INFO:Importing untrained model
2024-11-27 20:16:21,142:INFO:Declaring custom model
2024-11-27 20:16:21,142:INFO:Naive Bayes Imported successfully
2024-11-27 20:16:21,142:INFO:Cross validation set to False
2024-11-27 20:16:21,142:INFO:Fitting Model
2024-11-27 20:16:21,175:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-27 20:16:21,175:INFO:create_model() successfully completed......................................
2024-11-27 20:16:21,237:INFO:Initializing create_model()
2024-11-27 20:16:21,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:21,237:INFO:Checking exceptions
2024-11-27 20:16:21,237:INFO:Importing libraries
2024-11-27 20:16:21,237:INFO:Copying training dataset
2024-11-27 20:16:21,239:INFO:Defining folds
2024-11-27 20:16:21,240:INFO:Declaring metric variables
2024-11-27 20:16:21,240:INFO:Importing untrained model
2024-11-27 20:16:21,240:INFO:Declaring custom model
2024-11-27 20:16:21,240:INFO:Decision Tree Classifier Imported successfully
2024-11-27 20:16:21,242:INFO:Cross validation set to False
2024-11-27 20:16:21,242:INFO:Fitting Model
2024-11-27 20:16:21,276:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-27 20:16:21,276:INFO:create_model() successfully completed......................................
2024-11-27 20:16:21,325:INFO:Initializing create_model()
2024-11-27 20:16:21,325:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:21,325:INFO:Checking exceptions
2024-11-27 20:16:21,325:INFO:Importing libraries
2024-11-27 20:16:21,325:INFO:Copying training dataset
2024-11-27 20:16:21,325:INFO:Defining folds
2024-11-27 20:16:21,325:INFO:Declaring metric variables
2024-11-27 20:16:21,325:INFO:Importing untrained model
2024-11-27 20:16:21,325:INFO:Declaring custom model
2024-11-27 20:16:21,325:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-27 20:16:21,325:INFO:Cross validation set to False
2024-11-27 20:16:21,325:INFO:Fitting Model
2024-11-27 20:16:21,368:WARNING:c:\users\user\appdata\local\programs\python\python39\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-27 20:16:21,368:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-27 20:16:21,368:INFO:create_model() successfully completed......................................
2024-11-27 20:16:21,422:INFO:Initializing create_model()
2024-11-27 20:16:21,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:21,422:INFO:Checking exceptions
2024-11-27 20:16:21,422:INFO:Importing libraries
2024-11-27 20:16:21,422:INFO:Copying training dataset
2024-11-27 20:16:21,425:INFO:Defining folds
2024-11-27 20:16:21,425:INFO:Declaring metric variables
2024-11-27 20:16:21,426:INFO:Importing untrained model
2024-11-27 20:16:21,426:INFO:Declaring custom model
2024-11-27 20:16:21,426:INFO:K Neighbors Classifier Imported successfully
2024-11-27 20:16:21,427:INFO:Cross validation set to False
2024-11-27 20:16:21,427:INFO:Fitting Model
2024-11-27 20:16:21,463:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-27 20:16:21,463:INFO:create_model() successfully completed......................................
2024-11-27 20:16:21,508:INFO:Initializing create_model()
2024-11-27 20:16:21,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:21,508:INFO:Checking exceptions
2024-11-27 20:16:21,508:INFO:Importing libraries
2024-11-27 20:16:21,508:INFO:Copying training dataset
2024-11-27 20:16:21,508:INFO:Defining folds
2024-11-27 20:16:21,508:INFO:Declaring metric variables
2024-11-27 20:16:21,508:INFO:Importing untrained model
2024-11-27 20:16:21,508:INFO:Declaring custom model
2024-11-27 20:16:21,508:INFO:SVM - Linear Kernel Imported successfully
2024-11-27 20:16:21,508:INFO:Cross validation set to False
2024-11-27 20:16:21,508:INFO:Fitting Model
2024-11-27 20:16:21,542:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-27 20:16:21,542:INFO:create_model() successfully completed......................................
2024-11-27 20:16:21,605:INFO:Initializing create_model()
2024-11-27 20:16:21,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC9E82FCA0>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-27 20:16:21,605:INFO:Checking exceptions
2024-11-27 20:16:21,605:INFO:Importing libraries
2024-11-27 20:16:21,605:INFO:Copying training dataset
2024-11-27 20:16:21,610:INFO:Defining folds
2024-11-27 20:16:21,610:INFO:Declaring metric variables
2024-11-27 20:16:21,610:INFO:Importing untrained model
2024-11-27 20:16:21,611:INFO:Declaring custom model
2024-11-27 20:16:21,611:INFO:Dummy Classifier Imported successfully
2024-11-27 20:16:21,612:INFO:Cross validation set to False
2024-11-27 20:16:21,612:INFO:Fitting Model
2024-11-27 20:16:21,646:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-11-27 20:16:21,646:INFO:create_model() successfully completed......................................
2024-11-27 20:16:21,706:INFO:_master_model_container: 14
2024-11-27 20:16:21,706:INFO:_display_container: 2
2024-11-27 20:16:21,709:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')]
2024-11-27 20:16:21,709:INFO:compare_models() successfully completed......................................
